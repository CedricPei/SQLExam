[
  {
    "question_id": 1471,
    "result": {
      "judgement": "Predicted SQL correctly computes the ratio of EUR-paying customers to CZK-paying customers using equivalent counting logic, with no extraneous filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1472,
    "result": {
      "judgement": "Prediction matches the question intent—summing 2012 consumption for LAM customers and returning the customer with the minimum total—so no overturn needed.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1473,
    "result": {
      "judgement": "Predicted query matches gold logic: filters SME customers for 2013, averages consumption, divides by 12; no extra or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1476,
    "result": {
      "judgement": "Both queries compute CZK 2012 consumption minus EUR 2012 consumption using equivalent filters; predicted SQL aligns with the question and adds no unjustified predicates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1484,
    "result": {
      "judgement": "Predicted query filters Segment = 'discount' (lower-case), capturing zero rows and giving 0 difference, while data evidently stores 'Discount'; thus it returns the wrong answer.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1486,
    "result": {
      "judgement": "Predicted query correctly counts SME customers per currency and outputs the positive difference only when CZK exceeds EUR, satisfying the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1483,
    "result": {
      "judgement": "Predicted query correctly sums consumption for customer 6 over the specified August–November 2013 months using substr logic equivalent (and potentially more robust) to the gold; no requirements violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1479,
    "result": {
      "judgement": "Predicted query sums Amount*Price from transactions instead of using the Consumption field in yearmonth, so it measures spending rather than the specified gas consumption and returns a different year.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1507,
    "result": {
      "judgement": "Prediction correctly lists distinct transaction times for gas stations of chain 11 just like the gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1506,
    "result": {
      "judgement": "Prediction matches gold and correctly lists product descriptions for Czech Republic gas-station transactions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1493,
    "result": {
      "judgement": "Predicted query correctly filters February 2012 records and computes the share of customers whose consumption exceeds 528.3, matching the question semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1509,
    "result": {
      "judgement": "Predicted query correctly counts Czech gas station transactions occurring after 2012-01-01, matching the question without extraneous filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1501,
    "result": {
      "judgement": "Predicted query filters on transaction dates but the substring pattern is wrong, leading to no rows and missing countries; therefore it fails to answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1528,
    "result": {
      "judgement": "Predicted query uses lower-case 'premium', leading to zero matches and a 0% result, whereas correct case-sensitive value is 'Premium', so it fails to answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1498,
    "result": {
      "judgement": "Prediction takes the maximum single-row consumption in 2012, while the question (and evidence pointing to month substrings) asks for the highest total consumption per month, requiring aggregation; thus the predicted SQL is semantically incorrect.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1500,
    "result": {
      "judgement": "Predicted query applies a substring filter that yields no September-2013 transactions, returning no product descriptions, so it fails to answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1514,
    "result": {
      "judgement": "Predicted query correctly filters by the given date and time and returns the currency; extra duplicate rows do not violate the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1515,
    "result": {
      "judgement": "Predicted query correctly joins to customers and filters on the specified date/time; LIMIT 1 is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1521,
    "result": {
      "judgement": "Predicted query matches all stated filters and counts the relevant transactions just like the gold; no requirements are violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1505,
    "result": {
      "judgement": "Prediction correctly counts distinct EUR customers with at least one monthly consumption over 1000, whereas gold counts qualifying month records, not customers.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1331,
    "result": {
      "judgement": "Aggregating the amount is a reasonable interpretation of the singular-phrased question, so the SUM() is not a clear violation; prediction remains acceptable.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1312,
    "result": {
      "judgement": "Prediction matches gold logic and satisfies the question without extraneous conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1351,
    "result": {
      "judgement": "Prediction faithfully retrieves Brent Thomason’s major by joining member to major on link_to_major and filtering by first and last name, matching the question’s explicit requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1334,
    "result": {
      "judgement": "Predicted query correctly joins member with zip_code and filters for state = 'Illinois', returning first and last names as required.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1371,
    "result": {
      "judgement": "Prediction correctly counts members for the specified event; adding DISTINCT is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1340,
    "result": {
      "judgement": "Prediction matches the question’s requirements, computing spent in 2019 minus spent in 2020 with correct joins and no unjustified filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1525,
    "result": {
      "judgement": "Prediction correctly computes share of distinct customers with EUR on 2012-08-25, aligning with the wording, whereas gold counts each transaction, not each customer.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1533,
    "result": {
      "judgement": "Prediction returns the same set of customers’ August-2012 consumption values as the gold (extra CustomerID column is harmless), using correct unit-price and product filters; logic matches the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1352,
    "result": {
      "judgement": "Predicted query matches the required filters and counting logic, yielding the same result as gold; no extra or missing predicates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1339,
    "result": {
      "judgement": "The predicted query correctly averages costs for Elijah Allen’s expenses in September or October, matching the question and gold semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1375,
    "result": {
      "judgement": "Prediction matches gold and correctly returns first and last names of members in the specified department without unjustified filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1390,
    "result": {
      "judgement": "Predicted query correctly computes kickoff cost over total event cost; lack of joins in denominator doesn’t change outcome given every expense links to an event, so no explicit requirement is violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1524,
    "result": {
      "judgement": "Customer nationality could reasonably be taken from the customer’s Currency field (pred) or, lacking such a field, from the Country of the gas station linked to the transaction (gold); both yield consistent Czech-related codes, so the prediction is a valid alternative interpretation.",
      "verdict": false,
      "ambiguity": "ambiguous schema",
      "gold_correct": true
    }
  },
  {
    "question_id": 1322,
    "result": {
      "judgement": "Prediction correctly counts high-attendance events that are meetings, while gold excludes meetings, so gold is wrong and prediction is correct.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1357,
    "result": {
      "judgement": "Predicted SQL matches the gold and fulfills the question requirements without extra or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1359,
    "result": {
      "judgement": "Predicted query correctly computes the Advertisement budget ratio between the two named events; the extra type = 'Meeting' filter in gold is not explicitly required, so prediction is acceptable.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1392,
    "result": {
      "judgement": "Predicted query correctly selects the September 2019 income rows and returns the source with the maximum amount, matching the question, whereas the gold orders by source rather than amount.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1405,
    "result": {
      "judgement": "Predicted query correctly sums the amounts per category for the 'April Speaker' event and orders them ascending, matching the question and the gold logic/results.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1346,
    "result": {
      "judgement": "Prediction matches gold and satisfies the question without extra or missing filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1317,
    "result": {
      "judgement": "Predicted query correctly counts distinct members who attended the Women's Soccer event and have Medium T-shirt size; no unjustified filters are added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1378,
    "result": {
      "judgement": "Prediction matches gold logic exactly with only an alias difference; answers the question correctly.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1380,
    "result": {
      "judgement": "Prediction matches gold in summing spent where category equals 'Food'.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1409,
    "result": {
      "judgement": "Prediction matches the required sum of cost for 2019-08-20 exactly, with no superfluous filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1362,
    "result": {
      "judgement": "Predicted query appropriately filters by county and state and counts distinct cities, matching the question’s intent; no unjustified predicates are added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1398,
    "result": {
      "judgement": "Prediction meets all stated requirements, matching gold logic for selecting the event with max advertisement spend.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1344,
    "result": {
      "judgement": "Prediction matches the required filters and column selection exactly, satisfying the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1531,
    "result": {
      "judgement": "Prediction reasonably sums total spending across all transactions for each customer and computes weighted average price, matching a straightforward interpretation of the schema, whereas the gold query only looks at a single month and mis-aggregates unit prices, so the prediction should stand.",
      "verdict": false,
      "ambiguity": "ambiguous schema",
      "gold_correct": false
    }
  },
  {
    "question_id": 1399,
    "result": {
      "judgement": "Prediction correctly checks if at least one attendance record matches Maya Mclean and the Women’s Soccer event, answering the yes/no question accurately.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1361,
    "result": {
      "judgement": "Predicted query correctly sums the cost of all pizza expenses, matching the gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1435,
    "result": {
      "judgement": "Predicted query satisfies all stated filters and returning duplicates is acceptable for a list question, so it answers correctly.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1411,
    "result": {
      "judgement": "Prediction correctly lists the types of expenses linked to Sacha Harrison; using DISTINCT is acceptable for stating kinds of expenses.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1422,
    "result": {
      "judgement": "Prediction returns the distinct budget categories of events located at MU 215, matching the question and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1156,
    "result": {
      "judgement": "Prediction matches the question; duplicates are not explicitly disallowed so lack of DISTINCT is acceptable.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1526,
    "result": {
      "judgement": "Predicted query fails to retrieve 2012 or 2013 consumption, yielding NULL, and uses MAX rather than summing yearly totals, so it does not correctly compute the requested decrease rate; gold query is aligned with the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1381,
    "result": {
      "judgement": "Predicted query correctly returns each student’s first and last name whose attendance count exceeds 7, matching the question and the gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1323,
    "result": {
      "judgement": "Predicted query correctly selects event_name for events with attendance >20 and excludes fundraisers, matching the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1403,
    "result": {
      "judgement": "Predicted query correctly selects the closed event with the most negative remaining budget and returns its name, matching the question’s intent; no unjustified filters are added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1401,
    "result": {
      "judgement": "Predicted query returns the (total) cost for poster expenses tied to the September Speaker event, matching a reasonable reading of the singular word \"cost\"; no unjustified filters are added.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1464,
    "result": {
      "judgement": "Predicted query filters on the literal string '9/9/2019', which does not match the stored date format and therefore returns no rows, so it fails to list the students and amounts.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1338,
    "result": {
      "judgement": "Predicted query misses the event because it filters on exact date equality instead of the stored text with time stamp, returning no rows, thus failing to determine if each expense was approved.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1164,
    "result": {
      "judgement": "Prediction counts distinct female patients with thrombosis = 1 in 1997, satisfying the question; no invalid filters added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1162,
    "result": {
      "judgement": "Predicted query applies the same filters and counts patients identically to the gold (DISTINCT on primary key is benign).",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1427,
    "result": {
      "judgement": "Predicted query correctly filters events at MU 215 of type 'Guest Speaker' with spent = 0 and returns the required budget categories, matching the question; the extra column in gold is unnecessary.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1350,
    "result": {
      "judgement": "Predicted query returns no rows because the date literal lacks leading zero and misses the matching record, so it fails to give the event status, whereas the gold query returns \"Closed\".",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1155,
    "result": {
      "judgement": "Predicted query correctly joins Patient with Laboratory and applies LDH > 500, returning the requested columns; lack of DISTINCT only adds duplicates, which the question does not forbid, so semantics match the intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1187,
    "result": {
      "judgement": "Prediction is semantically identical to gold and satisfies the question’s filters; lack of an explicit COUNT is consistent with gold and acceptable.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1426,
    "result": {
      "judgement": "Predicted query correctly lists last names plus department and college for all club members majoring in Environmental Engineering, while the gold adds an extra position='Member' filter not explicitly required; this difference stems from an ambiguous reading of “members”, so the prediction stands.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1368,
    "result": {
      "judgement": "Predicted query correctly joins member to major and filters by the given phone number, matching the gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1356,
    "result": {
      "judgement": "Predicted query correctly selects the department(s) where the club President belongs, extra position column does not alter the answer.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1209,
    "result": {
      "judgement": "Predicted query fulfills all explicit requirements and matches gold semantics, so Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1152,
    "result": {
      "judgement": "The predicted query computes inpatient divided by outpatient, matching the provided evidence formula, and question phrasing is ambiguous, so no clear requirement is violated.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1171,
    "result": {
      "judgement": "Prediction correctly counts underage patients examined between 1990 and 1993, differing from gold only by DISTINCT which is reasonable for counting patients.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1185,
    "result": {
      "judgement": "Predicted query matches the logic but expresses the rate as a percent (×100) whereas gold gives the raw ratio; percentage vs ratio is an acceptable ambiguity for the term \"decrease rate\".",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1150,
    "result": {
      "judgement": "Predicted query computes the percentage of female patients born after 1930 exactly as requested, matching the gold logic without extraneous filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1175,
    "result": {
      "judgement": "Predicted query uses the examination date and the examination diagnosis as required, whereas the gold query uses laboratory date and patient-level diagnosis, so the prediction better matches the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1208,
    "result": {
      "judgement": "Prediction matches the question requirements and mirrors the gold logic exactly.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1376,
    "result": {
      "judgement": "Prediction satisfies the question; grouping choice is semantically equivalent and adds no improper filter.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1394,
    "result": {
      "judgement": "Prediction correctly counts members with the specified major; DISTINCT is benign and query matches intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1201,
    "result": {
      "judgement": "Predicted query joins to Examination without deduplicating patients, so varying numbers of exam rows per patient will bias the female-to-total ratio; gold query counts each patient once, matching the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1198,
    "result": {
      "judgement": "Predicted query only counts female patients whose APS diagnosis appears in the Examination table, missing those whose APS diagnosis is recorded only in the Patient table, so it under-reports the required count.",
      "verdict": true,
      "ambiguity": "ambiguous schema",
      "gold_correct": true
    }
  },
  {
    "question_id": 1235,
    "result": {
      "judgement": "Predicted query misses many qualifying patients, returning only 5 unique IDs while many more patients have RBC < 3.5; answer is incomplete.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1231,
    "result": {
      "judgement": "Predicted query satisfies all stated constraints (male, birth 1936-1956, CPK ≥250, distinct patients) and counts them; logic matches gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1189,
    "result": {
      "judgement": "Prediction compares ANA column to string and averages over all records, so it fails explicit conditions and returns wrong count; gold uses correct ANA Pattern field and appropriate filter.",
      "verdict": true,
      "ambiguity": "ambiguous schema",
      "gold_correct": true
    }
  },
  {
    "question_id": 1410,
    "result": {
      "judgement": "Prediction correctly filters by the given member, sums their expenses, and returns the full name (concatenated) and total cost, matching the question’s requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1238,
    "result": {
      "judgement": "Predicted query limits SLE filtering to Examination.Diagnosis, excluding patients whose SLE diagnosis is recorded only in Patient.Diagnosis, so it can miss the true oldest qualifying patient and yields a different ID; gold query follows the clearer patient-level field and is therefore correct.",
      "verdict": true,
      "ambiguity": "ambiguous schema",
      "gold_correct": true
    }
  },
  {
    "question_id": 1229,
    "result": {
      "judgement": "Prediction matches all stated requirements (TG >= 200, age > 50, distinct patients) and aligns with the gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1404,
    "result": {
      "judgement": "Prediction filters approved expenses and sums cost by expense description, matching the request, while gold omits the approval filter and returns the event’s type instead of expense type, so prediction is acceptable and gold appears wrong.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": false
    }
  },
  {
    "question_id": 1168,
    "result": {
      "judgement": "Prediction correctly finds the oldest SJS patient and returns one laboratory date and the computed age at first arrival, matching gold-output semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1460,
    "result": {
      "judgement": "Prediction correctly returns member’s full name (concatenated) and cost for the specified expense.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1192,
    "result": {
      "judgement": "Predicted SQL satisfies all stated requirements and matches gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1432,
    "result": {
      "judgement": "Prediction follows a reasonable reading (percentage of members who contributed 50) and violates no stated requirement.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1220,
    "result": {
      "judgement": "Predicted query correctly selects patients with UN = 29; duplicates are harmless and permissible, so its answer is semantically right.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1247,
    "result": {
      "judgement": "Predicted query correctly counts distinct male patients whose single lab record shows WBC in the normal range and FG abnormal, matching the stated criteria, while the gold query mis-orders OR/AND so it counts many patients without applying the WBC filter; thus Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1252,
    "result": {
      "judgement": "Predicted query correctly counts distinct patients whose IgG is >900 and <2000 and whose Symptoms field is not null, matching the stated criteria, whereas the gold query uses inclusive bounds and may double-count, so the prediction should stand.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1153,
    "result": {
      "judgement": "Predicted query returns the patient’s diagnosis paired with every lab date for ID 30609, matching the question and equivalent to the gold join on the unique ID.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1239,
    "result": {
      "judgement": "Prediction correctly finds patients with at least two HCT readings ≥52 and returns their ID and computed age, matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1243,
    "result": {
      "judgement": "Prediction correctly computes female share among abnormal PT records for patients >55, whereas gold divides by all records, so gold is wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1225,
    "result": {
      "judgement": "Predicted query fulfills the stated requirement by selecting patients with T-BIL ≥ 2.0 and returning GROUP_CONCAT of distinct IDs per sex, exactly matching the prompt and evidence; no substantive error found.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1281,
    "result": {
      "judgement": "Predicted query correctly returns the latest (maximum) birthday among patients whose GOT ≥ 60, matching the question’s requirement and the gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1030,
    "result": {
      "judgement": "Prediction matches the question requirements: it filters 2015/2016 season, counts draws per league, and returns the league with the highest count.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1169,
    "result": {
      "judgement": "The prediction counts male vs female abnormal‐UA records just like the gold, matching the stated thresholds; no extra or missing predicates are present, so it satisfies a reasonable reading of the question.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1275,
    "result": {
      "judgement": "Prediction follows evidence instructions and correctly counts distinct male patients with normal anti-centromere and anti-SSB levels; any discrepancy with gold arises from different but plausible encodings of “normal,” so prediction remains acceptable.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1157,
    "result": {
      "judgement": "Prediction uses diagnosis from Examination, yielding null/incorrect values and possible duplicates, thus fails to give the patients’ actual diseases.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1255,
    "result": {
      "judgement": "Predicted query joins Laboratory with Examination only on patient ID, inflating counts (N×M rows) and excludes patients lacking Examination rows, so it does not reliably identify the most common disease among all abnormal-IgM patients; therefore the Prover’s pass must be overturned.",
      "verdict": true,
      "ambiguity": "ambiguous schema",
      "gold_correct": true
    }
  },
  {
    "question_id": 1265,
    "result": {
      "judgement": "Predicted query filters on RNP = '-' or '+-' but database stores the equivalent normal values as 'negative' or '0', so it misses all qualifying patients and returns 0, violating the question; gold query uses correct values but its missing parentheses lets patients with RNP='negative' be counted even if not admitted, so it is also faulty.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1042,
    "result": {
      "judgement": "Predicted query correctly filters the 2009/2010 matches, computes average home vs away goals per league, and returns league names where home average is higher—matching the question and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1035,
    "result": {
      "judgement": "Prediction applies the correct numeric filter and returns the requested team_fifa_api_id column; duplicates do not violate the question wording, so it answers correctly.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1256,
    "result": {
      "judgement": "Prediction correctly counts distinct patients matching CRP='+' with Description NULL, whereas gold over-counts duplicated lab records, yielding a much larger, incorrect total.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1032,
    "result": {
      "judgement": "Predicted query correctly counts matches per league and returns the league with the maximum count; no extra or missing filters, so it satisfies the question, whereas the gold query relies on undefined behaviour by selecting a non-aggregated column without GROUP BY.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1057,
    "result": {
      "judgement": "Predicted query correctly computes average home_team_goal for Poland in 2010/2011 with equivalent filters and logic to gold; no unjustified predicates or omissions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1079,
    "result": {
      "judgement": "Predicted query correctly selects all player names with the maximum height, fulfilling the request; tie-handling difference from gold is acceptable.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1195,
    "result": {
      "judgement": "Predicted query multiplies laboratory rows for any patient with multiple Examination records, inflating the ALB values and giving a biased average; gold query applies each lab row once, matching the question’s intent.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1025,
    "result": {
      "judgement": "Predicted query correctly computes total goals per league for season '2015/2016' and returns the league with the maximum, matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1048,
    "result": {
      "judgement": "Prediction matches gold logic; returns player’s overall_rating for 2011 exactly as asked.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1088,
    "result": {
      "judgement": "Predicted query correctly returns distinct player names where both volleys and dribbling exceed 70, matching question intent and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1179,
    "result": {
      "judgement": "Prediction correctly selects the aCL IgM value for the specified patient and date, aligning with evidence; no requirement to return IgG or IgA.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1029,
    "result": {
      "judgement": "Predicted query correctly picks each team’s maximum buildUpPlaySpeed, ranks descending, and returns the speeds for the top-4 teams, matching the question, whereas the gold query sorts ascending and ignores team grouping, thus answering a different (and wrong) question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1105,
    "result": {
      "judgement": "Prediction matches gold semantics and correctly returns Francesco Migliore’s attacking work rate on 2015-05-01.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1084,
    "result": {
      "judgement": "Predicted query correctly counts distinct players born before 1986 whose defensive_work_rate is 'high', matching the question’s intent; differences from gold (using player_api_id vs player_name) are benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1098,
    "result": {
      "judgement": "Prediction still yields Ajax’s maximum chanceCreationPassing value along with the corresponding class, satisfying the question’s requirements despite using GROUP BY.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1040,
    "result": {
      "judgement": "Predicted query satisfies all stated requirements, computing average heading accuracy for players taller than 180 and returning top 10 names; differences from gold are implementation details only.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1124,
    "result": {
      "judgement": "Prediction matches the question, joining Player with Player_Attributes and filtering attacking_work_rate='high' just like gold; no extra or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1242,
    "result": {
      "judgement": "Predicted query computes age using the current year instead of the 1984 examination year, so it mis-identifies who was <50 at the time of the 1984 lab; gold query uses exam date correctly.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1103,
    "result": {
      "judgement": "Prediction matches question intent; LIMIT 1 is acceptable for a single rating on that date.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1078,
    "result": {
      "judgement": "Predicted query correctly returns the earlier birthday among the two named players, matching gold logic and satisfying the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1068,
    "result": {
      "judgement": "Predicted query correctly filters by height and date and computes AVG while naturally excluding NULL ratings, matching the question, whereas gold divides by all rows including NULLs.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1257,
    "result": {
      "judgement": "Prediction correctly counts distinct patients under 70 with creatinine ≥1.5, matching question intent and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1302,
    "result": {
      "judgement": "Prediction correctly counts distinct patients satisfying both conditions, whereas gold over-counts multiple lab/exam rows, so prediction matches the question and gold is faulty.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1122,
    "result": {
      "judgement": "Pred query correctly finds a player whose overall_rating equals the global maximum; adding LIMIT 1 is permissible since the question asks for the (singular) strongest player and does not require returning all ties.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1096,
    "result": {
      "judgement": "Predicted query correctly computes the average overall_rating for player_name 'Pietro Marino' with equivalent logic to gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1144,
    "result": {
      "judgement": "Predicted SQL reasonably returns finishing and curve for a heaviest-weight player, choosing the latest attributes, which is a valid reading of the unstated date requirement.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1036,
    "result": {
      "judgement": "Predicted query correctly lists team_long_name for teams whose 2012 buildUpPlayPassing value exceeds the 2012 average, matching the question’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1114,
    "result": {
      "judgement": "Predicted query correctly averages overall_rating for Marko Arnautovic within the specified date range; join via player_api_id is valid and no unwarranted predicates are added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1092,
    "result": {
      "judgement": "Prediction returns one league with the maximum 2008/2009 match count; although gold returns all tied leagues, the question asks for \"the\" league, so the prediction is semantically correct.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 854,
    "result": {
      "judgement": "Predicted query correctly retrieves latitude and longitude for the Australian Grand Prix circuit; duplicate rows are acceptable for this list-style question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1028,
    "result": {
      "judgement": "Pred query correctly identifies away teams in Scotland Premier League 2009/2010 and returns one of the top-winning teams; difference from gold is only tie-handling, which the question does not specify.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1141,
    "result": {
      "judgement": "Latest-only answer (Balanced) is a reasonable reading of “does the team have” since it implies current state, while gold lists all historical classes; both approaches are valid under the ambiguous wording.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 869,
    "result": {
      "judgement": "Predicted query correctly identifies constructor with top points in race 9 and returns its url; extra grouping is benign and doesn’t alter outcome.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1135,
    "result": {
      "judgement": "Predicted query correctly finds the four right-footed players with the lowest recorded potential, whereas the gold query seeks five high-potential rows and returns row ids, so gold is wrong and prediction stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1039,
    "result": {
      "judgement": "Predicted query correctly computes the average long_shots for the player and any difference from the gold (AVG vs SUM/COUNT) is immaterial given typical non-null data; no explicit requirement is violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1232,
    "result": {
      "judgement": "Predicted query applies the exact GLU ≥ 180 and T-CHO < 250 conditions, joins to Patient to retrieve ID, sex, and computed age; extra DISTINCT is unnecessary but harmless, so the query answers the question correctly.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1133,
    "result": {
      "judgement": "Prediction matches the question requirements; same filters and counting logic as gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 850,
    "result": {
      "judgement": "Prediction aligns with the question, selecting race names whose circuits are located in Germany with no extraneous filters; same logic as gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1136,
    "result": {
      "judgement": "Prediction correctly counts distinct players with max crossing and left foot, while gold counts attribute rows leading to duplicate overcount.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1076,
    "result": {
      "judgement": "Predicted query correctly computes each player's average ball control and subtracts them, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 868,
    "result": {
      "judgement": "Prediction returns correct latitude and longitude for Malaysian Grand Prix; extra duplicate rows do not violate the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1251,
    "result": {
      "judgement": "Prediction correctly counts distinct patients with IGG ≥ 2000, whereas gold wrongly restricts to patients appearing in Examination, so prediction satisfies the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1146,
    "result": {
      "judgement": "Predicted query matches the gold and correctly returns the team from the match with the maximum away_team_goal.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 862,
    "result": {
      "judgement": "Prediction matches the intended count of drivers who did not finish the 2007 Bahrain Grand Prix using correct filters; extra DISTINCT is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 892,
    "result": {
      "judgement": "Prediction incorrectly aggregates points rather than taking the single-row max the question/evidence specifies, so it returns the wrong driver.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 884,
    "result": {
      "judgement": "Predicted query correctly finds races whose year and month match those of the minimum date, satisfying the earliest recorded year-month requirement without extra filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 859,
    "result": {
      "judgement": "Predicted query correctly retrieves Bruno Senna’s Q1 time for raceId 354 using a driverId lookup; no unjustified filters are added and logic matches the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1058,
    "result": {
      "judgement": "Prediction correctly identifies that the shortest-height player group wins and returns a valid identifier for that player, matching the gold answer’s meaning.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 875,
    "result": {
      "judgement": "Predicted query correctly retrieves the season url for the year in which race 901 occurred, matching the gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 865,
    "result": {
      "judgement": "Predicted query correctly selects finished drivers of race 592, orders by earliest dob to find the oldest, and returns that driver; minor extra columns do not violate the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1091,
    "result": {
      "judgement": "Predicted query correctly counts matches in April 2009 for the Belgium Jupiler League and matches gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 895,
    "result": {
      "judgement": "Prediction matches the required filters and computes the same average lap time as the gold; no unjustified conditions are added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 902,
    "result": {
      "judgement": "Both queries follow a plausible but different reading of “track number”; predicted uses finishing position, gold uses championship standing, so prediction cannot be declared wrong outright.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 879,
    "result": {
      "judgement": "Both queries aim to retrieve the nationality of the driver with the maximum fastestLapSpeed, and the prediction numerically compares the speeds, matching the question’s intent; no clear error is evident in the prediction, so the Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 904,
    "result": {
      "judgement": "Predicted query correctly finds the race (name and year) with Michael Schumacher's overall fastest lap and matches the semantics of the question without spurious filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1094,
    "result": {
      "judgement": "Prediction fairly computes the percentage difference between the two players’ overall ratings by using a single representative value (average) per player, whereas the gold inflates the result by summing all historical rows; the predicted SQL aligns with the question’s intent, so keep the pass.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": false
    }
  },
  {
    "question_id": 880,
    "result": {
      "judgement": "Predicted query correctly gets Paul di Resta’s fastest-lap speeds for race 853 and the following race (854) and computes the percentage difference per the evidence, matching gold semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 931,
    "result": {
      "judgement": "Prediction matches question intent; computes the maximum fastestLapSpeed for the 2009 Spanish Grand Prix using equivalent logic to gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 930,
    "result": {
      "judgement": "Predicted query only returns a single race, whereas Lewis Hamilton achieved his top (rank=1) in multiple races; thus it gives an incomplete answer.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1113,
    "result": {
      "judgement": "Prediction correctly returns defenceAggressionClass for Hannover 96 on the specified date, while gold selects an unrelated column; prediction is semantically correct, gold is not.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1031,
    "result": {
      "judgement": "Predicted query properly filters 2013-2015 records with sprint_speed ≥97 and computes current age in years, while the gold subtracts datetime strings yielding only a crude year difference, so prediction is acceptable.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 937,
    "result": {
      "judgement": "Both prediction and gold select the finish time for the driver whose rank value is 2 in the 2008 Chinese Grand Prix; no requirement is violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1044,
    "result": {
      "judgement": "Predicted query correctly retrieves players born in October 1970 using equivalent substr conditions to the gold without extra or missing filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1107,
    "result": {
      "judgement": "Predicted query correctly finds the earliest date on which Kevin Constant achieved his maximum crossing score, while the gold query actually returns the latest date and ignores the crossing maximum requirement, so the Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 898,
    "result": {
      "judgement": "Prediction returns the correct youngest Japanese driver and his age using proper filtering, ordering, and age calculation, matching gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 897,
    "result": {
      "judgement": "Predicted query soundly selects the driver with the greatest summed wins, returning his full name, nationality, and maximum points—meeting the question’s intent; no clear requirement is violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1130,
    "result": {
      "judgement": "Prediction correctly lists short team names with chanceCreationPassingClass = 'Safe', matching question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 912,
    "result": {
      "judgement": "Predicted query matches gold and correctly retrieves circuitRef for Marina Bay Street Circuit.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1080,
    "result": {
      "judgement": "Pred counts unique players, aligning with “how many players”; gold counts attribute rows and over-counts.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1145,
    "result": {
      "judgement": "Predicted query correctly lists the 4 leagues with the highest match counts for season '2015/2016'; extra alphabetical tie-breaker is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 945,
    "result": {
      "judgement": "Predicted query correctly counts circuits in Adelaide, Australia; using COUNT(*) vs COUNT(circuitId) is equivalent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1147,
    "result": {
      "judgement": "Predicted query correctly returns any one player whose overall_rating equals the maximum, matching the question’s requirement; LIMIT 1 is acceptable since only one name is asked.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 951,
    "result": {
      "judgement": "Predicted query returns 1 constructor, but gold and question logic indicate there should be 2; prediction therefore under-counts and fails the requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1102,
    "result": {
      "judgement": "Predicted query correctly filters 2016-06-23 records with overall_rating 77, orders by earliest birthday to get the oldest player, and returns the player name, matching the question and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 955,
    "result": {
      "judgement": "Predicted query correctly selects winners (position=1), converts their milliseconds to seconds, restricts to years before 1975, and averages per year; minor numeric differences from gold stem from different conversion method, not a logical error.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 857,
    "result": {
      "judgement": "Prediction returns the correct latitude and longitude; extra duplicate rows do not violate the question’s intent of providing the coordinate position.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 950,
    "result": {
      "judgement": "Prediction uses per-race constructorResults instead of cumulative constructorStandings, so it returns several extra teams (e.g., McLaren) that did not have zero points in the standings after race 291, thus not satisfying the query.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 967,
    "result": {
      "judgement": "Prediction only returns the Dutch-driver count and omits the requested driver codes, violating an explicit requirement of the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1116,
    "result": {
      "judgement": "Prediction returns all players whose height equals the maximum, satisfying the request for the tallest players’ names; no improper filters added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 964,
    "result": {
      "judgement": "Predicted query correctly lists the code of all drivers whose nationality is American, matching the question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 872,
    "result": {
      "judgement": "Prediction matches the required filters and retrieves the driver code exactly like the gold; no extra or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 877,
    "result": {
      "judgement": "Prediction correctly selects the youngest driver who finished race 872 (latest dob), matching the gold result.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1139,
    "result": {
      "judgement": "Predicted query correctly filters by Belgian Jupiler League and the specific date, returning the home and away goals as requested.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 894,
    "result": {
      "judgement": "Prediction correctly retrieves the minimum lap time along with the corresponding driver and race, satisfying all explicit requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 994,
    "result": {
      "judgement": "Predicted query correctly aggregates constructor points at Monaco GP between 1980–2010 and returns the winning constructor’s total points, name, and nationality; column order difference is immaterial.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 960,
    "result": {
      "judgement": "Prediction matches the required filters and computes the requested average, aligning with the question and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 724,
    "result": {
      "judgement": "Predicted query correctly selects superhero names with blue eyes and blond hair, matching question intent and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 719,
    "result": {
      "judgement": "Predicted query correctly filters superheroes with Super Strength and height > 200 cm and counts them; no unjustified predicates are added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 978,
    "result": {
      "judgement": "Predicted query correctly lists each Austrian circuit with its latitude, longitude, and the number of races held there, matching the explicit “how many times” requirement, whereas the gold omits the counts.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 733,
    "result": {
      "judgement": "Prediction correctly counts Marvel-published superheroes whose eye colour is Gold; DISTINCT is harmless.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 738,
    "result": {
      "judgement": "Predicted query correctly returns superheroes whose durability attribute value is below 50 using proper joins without unjustified filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 745,
    "result": {
      "judgement": "Prediction matches the question and schema exactly, differing only by an innocuous CTE wrapper.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 751,
    "result": {
      "judgement": "Predicted query correctly lists five (distinct) power names for male superheroes as requested.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 764,
    "result": {
      "judgement": "Predicted query correctly retrieves the power_name values for hero_id 1; lack of DISTINCT is benign per guidance.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 962,
    "result": {
      "judgement": "Predicted query counts drivers who ever had a lap>50 (in any year) rather than restricting that condition to races between 2000-2005, inflating the numerator and giving 100% instead of ~65%; thus it fails the question’s time constraint.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 781,
    "result": {
      "judgement": "Predicted query correctly retrieves height_cm for heroes with eye colour Amber, matching gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 896,
    "result": {
      "judgement": "Predicted query counts Hamilton’s non-first race finishes since 2010 using the results table, which is a reasonable reading of the question; gold instead uses driverStandings, so the discrepancy is due to schema ambiguity rather than an error in the prediction.",
      "verdict": false,
      "ambiguity": "ambiguous schema",
      "gold_correct": true
    }
  },
  {
    "question_id": 747,
    "result": {
      "judgement": "Prediction correctly counts superheroes with NULL full_name; difference from gold (COUNT(*) vs COUNT(id)) is semantically equivalent since id is non-null primary key.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1002,
    "result": {
      "judgement": "Prediction matches the question, returning youngest driver's full name, nationality, and first race correctly.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 910,
    "result": {
      "judgement": "Prediction exactly matches gold and fulfills question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 765,
    "result": {
      "judgement": "Prediction counts distinct heroes with stealth power, matching the question; extra DISTINCT is harmless and satisfies the intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 769,
    "result": {
      "judgement": "Gold forgets to restrict to the durability attribute, whereas the prediction applies the proper durability filter and identifies the max for Dark Horse Comics, thus matching the question’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 901,
    "result": {
      "judgement": "Predicted query correctly lists each 2005-09 race with its circuit and location, matching gold results and meeting question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 933,
    "result": {
      "judgement": "Predicted query matches gold semantics, selecting Hamilton's positionOrder for the 2008 Chinese Grand Prix with no spurious predicates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 728,
    "result": {
      "judgement": "Predicted query filters Marvel heroes, counts each eye colour, and orders by count descending, satisfying the requested ranking; rank numbers are optional.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 940,
    "result": {
      "judgement": "Predicted query correctly counts drivers who finished the 2008 Chinese Grand Prix and have at least one race record, matching the question’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 794,
    "result": {
      "judgement": "Predicted query correctly finds heroes with the maximum Speed attribute, satisfying the question even if several tie, so Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 782,
    "result": {
      "judgement": "Predicted query correctly returns all superheroes whose eye and hair colour entries correspond to the colour “Black,” matching the question’s requirement; no unjustified filters were added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 786,
    "result": {
      "judgement": "Predicted query correctly counts heroes whose Strength equals the maximum Strength value, matching the question, whereas gold incorrectly compares to the overall maximum across all attributes.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 740,
    "result": {
      "judgement": "Predicted query correctly counts female heroes whose Strength attribute equals 100 and adds no unjustified filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 822,
    "result": {
      "judgement": "Prediction matches the question’s requirements exactly, counting superheroes with green skin and bad alignment; no extraneous or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 796,
    "result": {
      "judgement": "Prediction returns each attribute and its value for '3-D Man', matching the query intent and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 928,
    "result": {
      "judgement": "Question is ambiguous between fastest-lap rank (gold) and race-winning position (prediction); choosing position 1 is a reasonable interpretation, so prediction cannot be deemed wrong.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 981,
    "result": {
      "judgement": "Predicted query correctly identifies the youngest driver, finds his earliest qualifying race, and returns the year plus race name, date, and time (with an extra driver-name column that does not violate the question).",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 971,
    "result": {
      "judgement": "Prediction correctly selects the German driver with the earliest birth date, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 824,
    "result": {
      "judgement": "Predicted query correctly lists all superheroes having the 'Wind Control' power and orders their names alphabetically, matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 537,
    "result": {
      "judgement": "Prediction correctly counts posts owned by the user via user id lookup, matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 948,
    "result": {
      "judgement": "Both queries correctly compute the maximum points recorded for any British constructor, matching the question’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 758,
    "result": {
      "judgement": "Predicted query filters race='human' case-sensitively, yielding no rows, so it fails to return the hair colour(s) that exist for height 185 human superheroes.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 798,
    "result": {
      "judgement": "Returning the single distinct publisher name equally satisfies the question, which can reasonably be interpreted as asking which publisher these heroes share.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 717,
    "result": {
      "judgement": "Prediction correctly lists all power_name entries linked to superhero_name '3-D Man', matching the question and gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 567,
    "result": {
      "judgement": "Predicted query correctly counts posts whose OwnerUserId matches the user with display name \"Tiago Pasqualini\", satisfying the question just like the gold query.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 773,
    "result": {
      "judgement": "Prediction meets the requirement: it selects superheroes whose eye, hair, and skin colour IDs are all equal and returns their publisher, matching the question and gold semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 544,
    "result": {
      "judgement": "Predicted query returns the post’s stored LastEditorDisplayName, which is NULL, while the correct display name is obtainable via LastEditorUserId lookup; thus the prediction gives an incorrect answer.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 723,
    "result": {
      "judgement": "Predicted query correctly counts unique blue-eyed heroes with the Agility power and does not introduce unjustified filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 790,
    "result": {
      "judgement": "Predicted query correctly subtracts Emil Blonsky’s weight from Charles Chandler’s without any unwarranted conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 568,
    "result": {
      "judgement": "Predicted query correctly joins votes to users and filters by vote id 6347 to return the display name, matching the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 959,
    "result": {
      "judgement": "Predicted query returns a single lap (46) chosen as the absolute quickest lap time, whereas the question context and provided hint (“Only the time of the champion shows in the format …”) imply listing the fastest-lap number from every 2009 race for the champion; the gold query follows this logic and outputs all such lap numbers, so the prediction misses most required rows and is semantically wrong.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 963,
    "result": {
      "judgement": "Predicted query correctly counts distinct French drivers with a sub-120-second lap, while the gold counts all such lap records, conflicting with the question’s focus on drivers; prediction is correct, gold is not.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 737,
    "result": {
      "judgement": "Predicted query faithfully joins superhero to race and filters by superhero_name 'Copycat', answering the race; no requirements violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 549,
    "result": {
      "judgement": "Prediction matches the requirement by returning the post body whose Id equals the ExcerptPostId for tag 'bayesian'.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1003,
    "result": {
      "judgement": "Predicted query only considers a single raceId and therefore under-counts accidents; across all Canadian Grand Prix races the maximum per-driver accident count is 2, not 1.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 977,
    "result": {
      "judgement": "Prediction applies identical filters and aggregates as required, so it correctly counts disqualified finishers in races 51–99.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 750,
    "result": {
      "judgement": "Predicted query correctly joins gender table and averages weight_kg for rows where gender = 'Female', fully satisfying the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 572,
    "result": {
      "judgement": "Prediction matches the required filter exactly, returning the post’s ViewCount as asked.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 586,
    "result": {
      "judgement": "Predicted query correctly identifies the users who placed a 50-point bounty on posts whose titles contain \"variance\"; returning only DisplayName satisfies the “Which user” request.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 730,
    "result": {
      "judgement": "Predicted query correctly lists Marvel Comics superheroes with the 'Super Strength' power, matching gold semantics; minor potential duplicates are acceptable for a list.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 532,
    "result": {
      "judgement": "Prediction matches the question: it selects display names where CreationDate year is 2011, same as gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 633,
    "result": {
      "judgement": "Prediction uses posts.OwnerUserId to identify posts authored by slashnick and selects the post with highest AnswerCount, matching the question intent; gold uses postHistory path, both reasonable under schema; no explicit requirement violated.",
      "verdict": false,
      "ambiguity": "ambiguous schema",
      "gold_correct": true
    }
  },
  {
    "question_id": 988,
    "result": {
      "judgement": "Predicted query correctly filters German drivers born 1980–1985, computes their average pit-stop duration, orders by it ascending, and limits to the top 3; extra output column is harmless.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 592,
    "result": {
      "judgement": "Predicted query correctly counts users with more than five badges using equivalent aggregation logic to gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 743,
    "result": {
      "judgement": "Predicted query correctly computes the percentage of Bad-aligned heroes among all superheroes and counts those published by Marvel, matching gold results.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 634,
    "result": {
      "judgement": "Predicted query filters on posts.OwnerDisplayName and returns no rows, missing posts linked via users so it fails to answer; gold correctly joins users to posts and returns Harvey Motulsky.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 726,
    "result": {
      "judgement": "Predicted query correctly filters Marvel Comics heroes and orders them by descending height, which fulfills the request to rank them; including an explicit rank column is not strictly required.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 766,
    "result": {
      "judgement": "Predicted query filters on lowercase 'strength' and limits to one row, producing no result, so it fails to return the hero(s) with the highest Strength value.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 760,
    "result": {
      "judgement": "Predicted query correctly computes percentage of 150-180 cm superheroes whose publisher is Marvel, matching question intent; use of publisher_id=13 is a valid equivalent to name filter and produced same result as gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 678,
    "result": {
      "judgement": "Prediction matches the question, using equivalent filters and a benign extra tie-breaker on Id.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 739,
    "result": {
      "judgement": "Predicted query correctly selects superhero_name for heroes linked to the power 'Death Touch' without adding or omitting any filter.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 785,
    "result": {
      "judgement": "Prediction correctly lists superhero_name for those with Neutral alignment, matching question intent and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 672,
    "result": {
      "judgement": "Predicted query correctly counts distinct UK users having at least one post with FavoriteCount ≥4, matching “how many users”, whereas gold counts users per qualifying post and over-counts duplicates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 557,
    "result": {
      "judgement": "Pred query reasonably counts all high-score posts (including those without an owner) and measures how many are owned by elder users, matching a valid reading of the question; slight result difference arises from whether ownerless posts are in the denominator, an ambiguity the wording does not resolve.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 797,
    "result": {
      "judgement": "Predicted query matches the required filters and columns; no extra or missing predicates compared to gold, thus it answers the question correctly.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 704,
    "result": {
      "judgement": "Predicted query exactly matches the required filter and columns for the tag named 'sample'.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1011,
    "result": {
      "judgement": "Predicted SQL reasonably interprets “top 20 driver” as a driver who has ranked 1-20 in standings and correctly returns the one with the absolute minimum lap time; the gold instead lists 20 fastest drivers, so difference stems from an alternate reading of the question rather than an error in the prediction.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 705,
    "result": {
      "judgement": "Predicted query correctly retrieves the reputation and up-vote count of the user who authored the comment with the exact text \"fine, you win :)\", matching the gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 775,
    "result": {
      "judgement": "Prediction reasonably calculates the percentage of female superheroes with blue skin, and its LEFT JOIN choice is an acceptable interpretation of “all female superheroes,” matching the question’s intent.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 576,
    "result": {
      "judgement": "Predicted query correctly returns the commenting user’s DisplayName with appropriate join and filter, matching gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 732,
    "result": {
      "judgement": "Predicted query correctly identifies the publisher of the superhero with the minimum Speed attribute, matching the gold’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 825,
    "result": {
      "judgement": "Predicted query correctly retrieves the gender(s) of any superhero possessing the \"Phoenix Force\" power, matching question intent and mirroring gold logic without unwarranted filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 547,
    "result": {
      "judgement": "Prediction correctly counts posts whose owners are older than 65 and have score ≥20, matching the question’s requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 345,
    "result": {
      "judgement": "Predicted query only returns repeated 'Legal' values and omits 'Banned' and 'Restricted', so it does not fully answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 744,
    "result": {
      "judgement": "Predicted query computes the counts for DC and Marvel, subtracts them, and returns their absolute difference, which matches the intended numeric answer accepted by the task; no unwarranted filters are added.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 772,
    "result": {
      "judgement": "Prediction correctly filters female superheroes from Dark Horse Comics and lists their eye, hair, and skin colours as names, satisfying the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 368,
    "result": {
      "judgement": "Prediction calculates the percentage of cards with borderColor = 'borderless' exactly as required, using an equivalent COUNT expression to the gold; no extra or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 761,
    "result": {
      "judgement": "Predicted query correctly filters male superheroes whose weight exceeds 79% of the overall average weight, matching the question’s requirements with no extraneous conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 791,
    "result": {
      "judgement": "Prediction ignores heroes with NULL height, violating evidence that denominator must include all heroes, so it does not answer the question correctly.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 639,
    "result": {
      "judgement": "Predicted query filters on posts.OwnerDisplayName so finds zero rows and returns NULL, thus does not compute the requested percentage of Community posts tagged with R; therefore prediction is incorrect.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 571,
    "result": {
      "judgement": "Prediction correctly divides the count of user 24’s posts by the count of votes the same user cast, matching the problem statement, whereas the gold query mis-joins and simply returns the post count itself.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 779,
    "result": {
      "judgement": "Predicted query correctly counts the number of hero_power rows linked to the superhero named Amazo, matching the gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 806,
    "result": {
      "judgement": "Prediction matches question requirements exactly, retrieving the eye colour for the specified full name.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 405,
    "result": {
      "judgement": "Predicted query filters on language = 'Portuguese (Brasil)', but the data evidently stores it as 'Portuguese (Brazil)', yielding 0 instead of 7; thus it mis-counts the requested sets in the Commander block.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 598,
    "result": {
      "judgement": "Predicted query yields 0.0 while the correct computation (per evidence and gold SQL) is –9.54; the prediction therefore mis-computes the required percentage difference.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 792,
    "result": {
      "judgement": "Prediction correctly joins the three tables and filters by superhero_name to return Abomination's power(s).",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 800,
    "result": {
      "judgement": "Prediction correctly computes blue-eyed heroes as eye_colour_id = 7 over total heroes, matching the question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 422,
    "result": {
      "judgement": "Prediction matches the required filter and correctly returns the language for multiverseid 149934.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 665,
    "result": {
      "judgement": "Prediction satisfies all stated requirements and mirrors the gold logic for counting 2010 links on posts with ≤2 answers then dividing by 12.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 819,
    "result": {
      "judgement": "Predicted query counts superheroes with missing weight, compares eye_colour_id 7 vs 1, and subtracts the totals just like the gold; no requirement is violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 468,
    "result": {
      "judgement": "Predicted query correctly retrieves the Simplified Chinese translation for the set named 'Eighth Edition'.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 531,
    "result": {
      "judgement": "Prediction returns the higher-reputation user correctly; extra column and tie-handling difference are acceptable.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 533,
    "result": {
      "judgement": "Predicted query counts users whose last access timestamp is strictly greater than midnight of 2014-09-01, while gold excludes all activity on 2014-09-01; the question phrase \"after 2014/9/1\" reasonably supports either reading, so prediction is acceptable.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 539,
    "result": {
      "judgement": "Predicted query correctly joins posts to users and filters by the specified title to return the owner’s DisplayName, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 555,
    "result": {
      "judgement": "Prediction matches the gold’s logic—averaging scores of posts authored by the user named “csgillespie”—with no extraneous or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 573,
    "result": {
      "judgement": "Predicted query matches gold and fully satisfies the requirement to list comment texts with score 17.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 565,
    "result": {
      "judgement": "Prediction matches required filters and correctly maps ClosedDate to well-finished status; discrepancies are only in output casing.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 683,
    "result": {
      "judgement": "Denominator scope (all posts vs. 2011-only posts) is not stipulated; both queries count the targeted numerator but differ on a plausible ambiguity, so prediction cannot be declared wrong with certainty.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 563,
    "result": {
      "judgement": "Predicted query uses a different date literal format that yields no matching comment, so it returns no row while the gold gives FavoriteCount 3; therefore the prediction fails to answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 637,
    "result": {
      "judgement": "Predicted query correctly filters Mark Meckes’s own posts with zero comments and extracts the distinct tag names, matching the question’s intent; no clear requirement is breached despite differing from gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 578,
    "result": {
      "judgement": "Prediction matches the question, retrieving the post owner’s display name and reputation with correct join and filter.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 710,
    "result": {
      "judgement": "Predicted query correctly counts comments with score 0 for posts having exactly one comment, while gold wrongly filters on post score instead of comment score.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 604,
    "result": {
      "judgement": "Predicted query correctly averages upvotes and ages for users with more than 10 posts, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 629,
    "result": {
      "judgement": "Prediction correctly computes votes in 2010 divided by votes in 2011 with equivalent logic to gold; no unjustified filters added or removed.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 530,
    "result": {
      "judgement": "Prediction uses asciiName which is NULL for these cards, so it outputs no card names, failing to list the cards as required.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 669,
    "result": {
      "judgement": "Predicted query correctly finds the earliest vote date for user 'chl' using MIN aggregation, matching the question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 671,
    "result": {
      "judgement": "Prediction aligns with the question, using correct tables, filter on badge name, earliest date ordering, and returns the user’s display name; no extraneous predicates added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 595,
    "result": {
      "judgement": "Predicted query respects the explicit view-threshold on users and gives one reasonable reading of “only one post history per post,” while the gold query uses posts’ ViewCount and a different, debatable history criterion; given the ambiguity, the prediction cannot be deemed wrong with certainty.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": false
    }
  },
  {
    "question_id": 349,
    "result": {
      "judgement": "Prediction correctly counts rulings per card, returns the card with the maximum, and reports the promo flag; gold instead filters to promo cards and counts cards per artist, so it answers a different question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 208,
    "result": {
      "judgement": "Predicted query correctly counts hydrogen atoms per molecule label and returns the label with the highest count, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 227,
    "result": {
      "judgement": "Prediction matches the question’s requirements, computing 100*carcinogenic/total rounded to three decimals without adding or omitting conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 682,
    "result": {
      "judgement": "Prediction returns a post created in 2010 but outputs NULL for the owner display name; the question demands the owner’s display name, so result is incomplete/incorrect.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 694,
    "result": {
      "judgement": "Predicted query lists the 10 newest comments but fails to fetch users’ display names (returns NULL because it does not join to users), so it does not satisfy the question’s requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 379,
    "result": {
      "judgement": "Prediction matches the question and gold logic; no extraneous conditions added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 240,
    "result": {
      "judgement": "Predicted query correctly retrieves distinct elements for molecule TR004 exactly as requested.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 707,
    "result": {
      "judgement": "Prediction correctly filters posts by view range and returns a highest-score comment; extra Id tie-breaker is harmless.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 253,
    "result": {
      "judgement": "Prediction matches gold logic and satisfies request for elements involved in triple bonds; no unjustified predicate or omission found.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 409,
    "result": {
      "judgement": "Predicted query matches filters for pre-modern format, specified ruling text, and single-face cards, returning the card count exactly as requested.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 327,
    "result": {
      "judgement": "Predicted query correctly lists molecule_ids whose label is '-' and have atom counts greater than 5, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 440,
    "result": {
      "judgement": "Prediction matches gold and satisfies the question by returning languages for the specified card name.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 341,
    "result": {
      "judgement": "Predicted query correctly lists names of borderless cards lacking the powerful-foil pair, whereas gold omits the foil-id check and only returns rows with null cardKingdomId, making gold incomplete.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 640,
    "result": {
      "judgement": "Prediction filters by posts.OwnerDisplayName, ignoring users.DisplayName and thus misses posts whose display name is stored only in users, so it does not implement the requested totals.",
      "verdict": true,
      "ambiguity": "ambiguous schema",
      "gold_correct": false
    }
  },
  {
    "question_id": 358,
    "result": {
      "judgement": "Prediction gives the correct borderColor even if repeated; duplicates are acceptable for this question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 347,
    "result": {
      "judgement": "Prediction returns each Stephen Daniele card together with its ruling text and a Yes/No indication of missing/degraded properties (hasContentWarning), matching the question’s intent; no substantive error found.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 473,
    "result": {
      "judgement": "Prediction correctly checks all sets containing the card and answers “No,” matching question intent; gold is also correct.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 685,
    "result": {
      "judgement": "Predicted query returns no rows because it joins posts on title instead of PostId and therefore fails to fetch view count or user, so it does not answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 377,
    "result": {
      "judgement": "Predicted query wrongly excludes rows whose subtypes string merely contains ‘Angel’; evidence specifies the test is subtypes != 'Angel', so result 0 is incorrect while gold’s 3 matches question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 487,
    "result": {
      "judgement": "Prediction filters on card name instead of set membership and returns NULL, so it fails to answer the percentage for the set.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 40,
    "result": {
      "judgement": "The prediction averages multiple SAT records per school, which can alter rankings and yields a different phone number than simply selecting the school record with the lowest reading average; this extra averaging is not required by (and may contradict) the question, so the predicted answer is not reliably correct.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 687,
    "result": {
      "judgement": "Predicted query returns 3 comments but the correct count for the highest-scored post is 35; prediction mis-identifies the post (or mishandles ties) whereas gold logic correctly targets the max-score post.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 716,
    "result": {
      "judgement": "Predicted query measures distinct users, a reasonable reading of “percentage of the users,” while gold measures comments; the wording allows either interpretation so prediction isn’t clearly wrong.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 407,
    "result": {
      "judgement": "Prediction returns the same subtype-supertype combinations for German cards as gold, just without duplicate rows, which still fulfills “list all types”; no requirement for duplicates was stated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 198,
    "result": {
      "judgement": "Prediction follows the evidence formula (single bonds divided by carcinogenic atom count) while gold averages per molecule; the wording allows either, so prediction cannot be deemed wrong.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 72,
    "result": {
      "judgement": "The prediction sums enrollment for all matching State Special School records in Fremont with Academic Year = '2014-2015', giving a single count (375) that directly answers “How many students ... for the 2014-2015 academic year?”. The gold query returns two separate rows instead of one aggregate and relies on a year BETWEEN 2014 AND 2015 filter, which is a looser interpretation. Thus the prediction is semantically correct and should stand.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 424,
    "result": {
      "judgement": "Prediction matches the required proportion calculation with correct filters and no extraneous conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 344,
    "result": {
      "judgement": "Predicted query returns the distinct card names that are mythic and banned in Gladiator, matching the essential request; gold lists individual print ids, so difference stems from interpretation of listing prints vs card names.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 92,
    "result": {
      "judgement": "Predicted query uses >6000 and <10000 as required by “more than… but less than…”, whereas gold’s BETWEEN is inclusive; thus prediction is faithful and should stand.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 352,
    "result": {
      "judgement": "Predicted query measures what percentage of cards have a Chinese-Simplified entry (cards count in denominator), matching the plain reading “percentage of the cards available in Chinese Simplified”, whereas the gold query divides by all card-language rows, so it instead measures what share of translation rows are Chinese. Thus the prediction aligns with the question and the gold does not.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 215,
    "result": {
      "judgement": "Predicted query counts all iodine or sulfur atoms in molecules that have any single bond and returns a single total, while question more naturally (and gold) asks for separate counts of atoms actually involved in single bonds; thus prediction is semantically off.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 469,
    "result": {
      "judgement": "Prediction correctly checks whether any set containing 'Angel of Mercy' has a non-NULL mtgoCode, answering the yes/no question; differences stem from alternative reading of whether to report each printing.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 115,
    "result": {
      "judgement": "Predicted query correctly identifies the south-Bohemia district(s) with the maximum inhabitants and computes male-client percentage; result mismatch is only a tie-handling difference, not an error.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 383,
    "result": {
      "judgement": "Prediction matches gold logic, correctly counting white-bordered cards with banned status.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 366,
    "result": {
      "judgement": "Predicted query correctly lists the play formats for \"Benalish Knight\"; minor duplication differences in the gold arise from multiple card rows but do not affect correctness.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 427,
    "result": {
      "judgement": "Predicted query correctly returns distinct languages for set code ARC with mcmName Archenemy, matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 412,
    "result": {
      "judgement": "Predicted query enforces all requested filters and returns same French names as gold; using type LIKE is semantically sound.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 472,
    "result": {
      "judgement": "Predicted query appropriately counts sets in the Ice Age block that have an Italian translation, and although it omits DISTINCT it yields correct set count given one translation per language-set; no explicit requirement violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 484,
    "result": {
      "judgement": "Prediction correctly returns the Italian names of cards in Coldsnap at the maximum converted mana cost, whereas gold returns English names, so prediction is correct and gold is faulty.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 195,
    "result": {
      "judgement": "Predicted query correctly identifies the bond_type with the highest count and adds only a benign alphabetical tiebreaker, fully satisfying the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 486,
    "result": {
      "judgement": "Predicted query correctly computes the percentage of Coldsnap cards whose converted mana cost equals 7, matching the gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 137,
    "result": {
      "judgement": "Prediction filters on district name equal to literal 'Branch location 1' instead of the numeric branch/district id 1, giving 0 instead of the actual 47 accounts, so it does not answer the question correctly.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 416,
    "result": {
      "judgement": "Predicted query joins cards.id to foreign_data.multiverseid instead of the documented foreign key foreign_data.uuid = cards.uuid, so it fails to identify French translations and returns 0%, violating the question requirements.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 212,
    "result": {
      "judgement": "Pred counts total atoms per element matching evidence definition, while gold counts distinct molecules, so pred meets question and schema; uphold and mark gold likely faulty.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 459,
    "result": {
      "judgement": "Predicted query correctly identifies the higher-cost card (Serra Angel) and, despite duplicate rows, does not violate any explicit requirement of the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 466,
    "result": {
      "judgement": "Predicted query correctly counts cards illustrated by Adam Rex in the set whose German translation is 'Hauptset Zehnte Edition'; extra join to sets is harmless.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 228,
    "result": {
      "judgement": "Predicted query correctly computes the ratio of hydrogen atoms to total atoms for molecule TR206 and rounds to four decimals.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 213,
    "result": {
      "judgement": "Prediction correctly fetches the bond_type for the specified atom pair with symmetric condition, matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 263,
    "result": {
      "judgement": "Predicted query reasonably filters by bond_type='-' and computes chlorine share among atoms tied to single bonds, a plausible reading of \"among the single bond molecules\"; no clear violation of requirements is evident.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 242,
    "result": {
      "judgement": "Prediction meets all stated requirements and is semantically equivalent to the gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 474,
    "result": {
      "judgement": "Predicted query omits the explicit requirement that translation be non-null, thus may count sets lacking an actual Italian translation, violating the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 12,
    "result": {
      "judgement": "Prediction correctly computes the maximum free-meal eligibility rate among schools whose SAT excellence rate exceeds 0.3, matching the question’s requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 255,
    "result": {
      "judgement": "Prediction computes the required percentage over single bonds exactly as specified, matching gold logic and formatting.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 480,
    "result": {
      "judgement": "Predicted query wrongly filters Italian rows by the English name, yielding no rows, while gold correctly joins on uuid and returns the Italian flavor text.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 230,
    "result": {
      "judgement": "Predicted query correctly lists the molecule’s elements along with the label; duplicate rows do not violate any explicit requirement in the question, so it answers adequately.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 5,
    "result": {
      "judgement": "Prediction matches the question’s requirements (count of distinct schools with AvgScrMath > 400 and Virtual = 'F').",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 529,
    "result": {
      "judgement": "Prediction rightly requires at least one Korean translation and zero Japanese translations, matching the question, whereas the gold query only checks for Korean and ignores Japanese absence, so gold is wrong and Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 415,
    "result": {
      "judgement": "Predicted query filters status = 'legal' (lower-case), which matches no rows in this database, giving NULL, whereas the question requires the actual commander cards whose status value is 'Legal'.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 243,
    "result": {
      "judgement": "Predicted query properly returns bonds that contain both a phosphorus atom and a nitrogen atom, matching the question’s intent; no unjustified filters are added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 207,
    "result": {
      "judgement": "Pred query correctly lists elements actually connected by '=' bonds, while gold over-includes any element in molecules that merely contain such a bond.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 95,
    "result": {
      "judgement": "Predicted query enforces both required conditions—youngest clients and districts with the highest average salary—while gold ignores the salary condition; therefore prediction is semantically correct and should stand.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 118,
    "result": {
      "judgement": "Predicted query counts distinct accounts, which matches a reasonable reading of “percentage of accounts,” and adds no unjustified filters; difference from gold (row-level vs account-level) is an acceptable alternative interpretation.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 356,
    "result": {
      "judgement": "Prediction correctly counts rows where power equals '*', matching the definition of infinite power given; identical to gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 260,
    "result": {
      "judgement": "Predicted query properly counts distinct atoms of phosphorus or bromine that belong to any molecule having at least one triple bond, matching the question; no extra or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 226,
    "result": {
      "judgement": "Prediction omits the required rounding to exactly five decimal places, returning 3.846154 instead of 3.84615, so it fails the explicit formatting requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 239,
    "result": {
      "judgement": "Predicted query properly counts bonds where atom 19 appears in either column, aligning with the question, while gold ignores atom_id2 and can miss connections.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 465,
    "result": {
      "judgement": "Prediction checks for a Korean-language printing of the card rather than a Korean version/translation of the set that contains it, so it answers the wrong question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 518,
    "result": {
      "judgement": "Prediction correctly identifies the format(s) with the greatest count of banned cards and lists each banned card in that/those format(s), satisfying the question’s requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 249,
    "result": {
      "judgement": "Prediction retrieves elements of both atoms linked to the bond without adding extraneous constraints, fully satisfying the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 479,
    "result": {
      "judgement": "Predicted query correctly counts cards in Coldsnap with converted mana cost >5 whose power is '*' or NULL, matching the question and gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 200,
    "result": {
      "judgement": "Predicted query correctly returns molecules that have a triple bond and a carcinogenic label, matching the question and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 528,
    "result": {
      "judgement": "Predicted query correctly lists each card from the Hour of Devastation set along with every format where its legality status is Legal, matching the question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 391,
    "result": {
      "judgement": "Predicted query uses the same join and filters as the gold (only lacks DISTINCT), so it answers the question; duplicate rows are permissible for a \"which\" list.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 282,
    "result": {
      "judgement": "Prediction multiplies the hydrogen proportion by 100, returning a percentage (36.17) instead of the requested ratio defined as count_h / total_atoms (~0.36), so it fails to follow the explicit ratio definition.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 41,
    "result": {
      "judgement": "Predicted query correctly filters exclusively virtual schools, ranks within each county by average reading score, and returns school names within top 5, matching the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 414,
    "result": {
      "judgement": "Predicted query matches the required filters and correctly lists the translation language(s) for the 180-card Ravnica set.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 206,
    "result": {
      "judgement": "Prediction matches gold and plausibly returns the elements of the atoms in the given bond; no clear evidence the missing join to atom_id2 is required, so no violation is proven.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 218,
    "result": {
      "judgement": "Predicted query correctly counts carcinogenic molecules that entirely lack fluorine, whereas gold erroneously counts those that merely have any non-fluorine atom, so prediction is semantically right and gold is wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 220,
    "result": {
      "judgement": "Predicted query correctly lists the first three distinct element names for molecule TR000 in alphabetical order, matching the question’s requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 77,
    "result": {
      "judgement": "Predicted query filters on a non-existent literal 'Kindergarten-9th Grade', yielding no rows, so it fails to list the two Los Angeles K-9 schools and their FRPM percentages that exist per database.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 236,
    "result": {
      "judgement": "Prediction satisfies the question, matching gold semantics; no unwarranted predicates added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 232,
    "result": {
      "judgement": "Predicted query correctly retrieves the first three alphabetically-ordered molecules that both have a single bond and are non-carcinogenic, matching all stated requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 93,
    "result": {
      "judgement": "Predicted SQL applies correct filters but case-sensitive value mismatch results in zero count, thus not answering the question correctly.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 25,
    "result": {
      "judgement": "Pred query reasonably interprets \"in Riverside\" as the county, correctly averaging math scores per school and returning funding type, so its larger result set is acceptable; difference with gold stems from ambiguous locality reference.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 462,
    "result": {
      "judgement": "The question could be read as asking for a single Italian set name, and the prediction correctly finds a valid set containing the card; limiting to one row is thus a reasonable interpretation.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 39,
    "result": {
      "judgement": "Predicted query applies the same county and 1980 OpenDate filters and computes the average NumTstTakr, matching the question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 245,
    "result": {
      "judgement": "Predicted query correctly divides bond count by distinct iodine atoms, whereas gold divides by duplicate rows equaling bonds and yields 1, so gold is wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 477,
    "result": {
      "judgement": "Predicted query correctly filters cards from set 'Coldsnap' and returns the subset of the three specified artists who appear, matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 248,
    "result": {
      "judgement": "Predicted query lists each atom that participates in any triple bond of molecule TR041, which satisfies the ask for \"atoms of the triple bond\" even though the gold returns them in ordered pairs; both are valid interpretations.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 62,
    "result": {
      "judgement": "Predicted query applies the correct county, charter, and percent filters and counts the qualifying schools, matching the intended semantics; no explicit requirement is violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 268,
    "result": {
      "judgement": "Query only retrieves the element for atom_id, omitting atom_id2, so it returns at most one element instead of both atoms in the bond.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 522,
    "result": {
      "judgement": "Predicted query meets the conditions (edhrecRank=1, banned status) and returns the correct card-format pairs, only with harmless duplicates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 138,
    "result": {
      "judgement": "Predicted query correctly identifies districts with the second-highest 1995 crime total and counts male clients there, matching the question’s intent without extraneous filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 89,
    "result": {
      "judgement": "Prediction miscounts because it uses a case-mismatching region string and returns 0 instead of the correct 13 accounts.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 281,
    "result": {
      "judgement": "Predicted query correctly counts (tallies) the elements for the 4th atom in carcinogenic molecules and respects the required filter; the extra LENGTH condition in gold and the absence of counts stem from an ambiguous reading of “tally”, so the Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 201,
    "result": {
      "judgement": "Prediction only counts atom_id endpoint of each double bond (ignores atom_id2 and all other atoms in those molecules), so the percentage is computed on an incomplete and duplicate set of atoms and does not answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 112,
    "result": {
      "judgement": "Predicted query returns the district of the account via the disp->account path, matching a natural reading of “district where she opened her account,” and yields the same result as gold; no unjustified filters are added.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 186,
    "result": {
      "judgement": "Prediction counts male versus total clients with weekly‐statement frequency and matches the question; any small difference vs. gold comes only from treating each client once, a reasonable interpretation.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 17,
    "result": {
      "judgement": "Predicted query correctly lists charter numbers ordered by their AvgScrWrite > 499, satisfying the ranking request; differences are stylistic only.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 24,
    "result": {
      "judgement": "Prediction satisfies both meal-eligibility and ≥1500-score conditions and returns correct school names, matching gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 129,
    "result": {
      "judgement": "Prediction returns the districts associated with the ten largest January-1996 non-credit-card withdrawal amounts, matching the \"top ten withdrawals\" wording, while gold simply lists ten distinct districts alphabetically, ignoring amount; thus prediction is correct and gold is not.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 36,
    "result": {
      "judgement": "Predicted query correctly finds the school(s) with the maximum NumGE1500 and returns the administrators’ first- and last-name fields, satisfying the question’s requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 50,
    "result": {
      "judgement": "Predicted query returns the physical Street column instead of the requested postal/mailing MailStreet column, violating an explicit requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 234,
    "result": {
      "judgement": "Predicted query correctly counts bonds of molecule TR009 where either atom side is TR009_12, whereas gold erroneously filters for atoms 1 and 2, so prediction matches the question and gold is wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 169,
    "result": {
      "judgement": "Predicted query counts loans associated with any male-linked account while gold limits to male owners; the question doesn’t specify ownership, so either interpretation is acceptable and predicted satisfies the stated requirement.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 100,
    "result": {
      "judgement": "Predicted SQL aligns with the question’s filters and reasonably interprets “among the account opened” by requiring the client to be linked to an account; no extraneous restriction is added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 98,
    "result": {
      "judgement": "Predicted query finds accounts whose minimum loan equals the global minimum across all 1997 loans and only then filters for weekly issuance, so it can miss the lowest-amount weekly accounts; gold correctly restricts to weekly issuance before taking the minimum and returns account 176, whereas prediction returns none.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 45,
    "result": {
      "judgement": "Prediction matches the question’s requirement, listing each Ricci Ulrich–managed school with its average writing score.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 136,
    "result": {
      "judgement": "Predicted query correctly counts loans of at least 250,000 approved between the given dates for accounts with monthly statements, matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 273,
    "result": {
      "judgement": "Predicted query measures the share of carcinogenic molecules that contain chlorine, whereas the question/evidence expects the share of chlorine atoms among all atoms in carcinogenic molecules; thus prediction is semantically wrong.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 79,
    "result": {
      "judgement": "Prediction matches question intent and applies correct filters; identical to gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 117,
    "result": {
      "judgement": "Prediction correctly computes 100 × (sum amount of status='A') / total amount, matching the requested percentage.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 152,
    "result": {
      "judgement": "Prediction averages over each qualifying district once, matching the question, while gold weights districts by every account and inflates the average, so prediction is correct and gold is not.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 194,
    "result": {
      "judgement": "Prediction satisfies all stated filters and returns client_id and computed age exactly as required; no extraneous conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 145,
    "result": {
      "judgement": "Predicted query correctly returns client IDs of card holders with 1998 credit-card withdrawals below the average of such withdrawals, matching the question, whereas the gold returns account IDs and uses an average over all 1998 transactions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 85,
    "result": {
      "judgement": "Prediction returns the percentage of eligible free meals and the district code for schools whose administrator first name is Alusine, matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 189,
    "result": {
      "judgement": "Predicted query joins through disp to ensure the accounts truly belong to the specified female clients and applies both global-minimum constraints exactly as phrased; the gold joins by district (mixing in unrelated accounts) and uses a different salary criterion, so the prediction is a defensible reading while the gold is likely wrong.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": false
    }
  },
  {
    "question_id": 99,
    "result": {
      "judgement": "Predicted query applies the duration >12 and 1993 opening-date filters, then finds the account whose loan amount is globally maximal; this satisfies the question, and the extra column (amount) is harmless. Gold query is also correct. No ambiguity involved.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 128,
    "result": {
      "judgement": "Predicted query correctly lists the nine districts with the largest counts of female clients, ordering by descending count and returning district names with their counts.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 159,
    "result": {
      "judgement": "Prediction returns the same set of cash-withdrawal transactions for client 3356 (adds extra columns but satisfies the question), so no error found.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 119,
    "result": {
      "judgement": "Predicted query meets all stated requirements (1993 accounts with \"POPLATEK PO OBRATU\" frequency) and returns correct fields, matching gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  }
]