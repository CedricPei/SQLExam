[
  {
    "question_id": 1473,
    "result": {
      "judgement": "Predicted query matches gold logic: computes average consumption of SME customers for 2013 and divides by 12.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1480,
    "result": {
      "judgement": "Predicted query matches gold in logic and satisfies requirement to return month with highest SME gas consumption in 2013.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1476,
    "result": {
      "judgement": "Predicted query correctly computes CZK minus EUR consumption for 2012, matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1486,
    "result": {
      "judgement": "Prediction subtracts counts of CZK vs EUR SME customers, matching the question’s requirement just like the gold; difference in DISTINCT does not alter correctness given unique CustomerID.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1479,
    "result": {
      "judgement": "Prediction correctly groups CZK records by year, sums consumption, picks the max year (2013); extra column is harmless.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1507,
    "result": {
      "judgement": "Prediction matches the query intent; ORDER BY addition is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1484,
    "result": {
      "judgement": "Predicted query uses Segment = 'discount', which fails to match the actual 'Discount' values, returning 0 instead of the correct 176 difference; it therefore does not satisfy the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1493,
    "result": {
      "judgement": "Prediction correctly computes the percentage of February-2012 customers whose consumption exceeds 528.3, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1498,
    "result": {
      "judgement": "Predicted query only finds the largest single customer-month record, while the question asks for the maximum total consumption of any month in 2012, which requires summing per month first; thus the prediction violates the required aggregation.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1521,
    "result": {
      "judgement": "Predicted query matches all stated filters and counts the same transactions as gold, satisfying the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1490,
    "result": {
      "judgement": "Predicted query excludes LAM customers who lack any consumption record, so its denominator is smaller than the required total number of LAM customers; this inflates the percentage and violates the given formula.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1528,
    "result": {
      "judgement": "Predicted query filters for segment='premium' in lowercase, yielding zero and thus fails to compute the actual percentage of Premium stations in SVK, whereas gold correctly matches the data and returns 35.68%.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1312,
    "result": {
      "judgement": "Predicted query matches the gold and correctly retrieves Angela Sanders’s major using her first and last name.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1506,
    "result": {
      "judgement": "Predicted query correctly lists product descriptions for Czech gas-station transactions; duplicates are acceptable because the question did not demand uniqueness, so Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1514,
    "result": {
      "judgement": "Predicted query retrieves the customer currency for the specified date/time and adds no unjustified filters; the LIMIT 1 is acceptable for the singular phrasing, so prediction is fine.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1515,
    "result": {
      "judgement": "Predicted query correctly joins transactions with customers, applies the intended date-time filters, and retrieves the Segment; the extra LIMIT 1 is benign given the singular phrasing of the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1509,
    "result": {
      "judgement": "Predicted query satisfies counting Czech gas-station transactions with date strictly past 2012-01-01, matching a literal reading of “after 2012/1/1”; no unwarranted predicates are added.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1331,
    "result": {
      "judgement": "Predicted query returns the total amount while gold lists each amount; question wording allows either and both yield same result, so no substantive violation.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1340,
    "result": {
      "judgement": "Predicted SQL correctly computes total spent for 2019 and 2020 and returns their difference (2019 minus 2020), matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1483,
    "result": {
      "judgement": "Predicted query uses the wrong table and returns NULL, while gold correctly sums Consumption for customer 6 between 201308 and 201311; prediction does not answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1501,
    "result": {
      "judgement": "Predicted query rightly filters transactions whose own date lies in June-2013 and lists the associated gas-station countries, whereas the gold query filters by customer’s month record and can pick transactions from other months, so the prediction better matches the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1533,
    "result": {
      "judgement": "Predicted query returns the requested consumption values for customers whose unit price on product 5 exceeded 29 and whose consumption record is for 201208; extra join to customers adds no restrictive filter.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1351,
    "result": {
      "judgement": "Prediction matches gold and correctly retrieves Brent Thomason’s major without extra or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1371,
    "result": {
      "judgement": "Predicted query correctly counts attendance rows for the specified event, matching the question intent and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1323,
    "result": {
      "judgement": "Predicted query correctly filters non-fundraiser events and keeps those with attendee count > 20, matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1339,
    "result": {
      "judgement": "Predicted query matches the question: averages Elijah Allen’s expenses where month is 09 or 10, same as gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1380,
    "result": {
      "judgement": "Prediction matches question requirements exactly; no violations found.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1505,
    "result": {
      "judgement": "Prediction counts distinct customers with euro currency whose monthly consumption exceeds 1000, matching the question, whereas gold erroneously counts month rows, over-counting customers.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1357,
    "result": {
      "judgement": "Prediction matches gold: it selects date_received from income for member Connor Hilton with source='Dues', satisfying the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1378,
    "result": {
      "judgement": "Predicted query correctly computes the maximum spent amount as asked.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1390,
    "result": {
      "judgement": "Predicted query applies the correct formula, obtaining the Yearly Kickoff cost and dividing by overall cost; the broader denominator still satisfies a reasonable reading of “total cost for all event,” and no unjustified filters are added.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1368,
    "result": {
      "judgement": "Predicted query exactly matches gold intent and meets question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1399,
    "result": {
      "judgement": "Predicted query correctly checks for Maya Mclean’s attendance of the Women’s Soccer event and returns a row when she did attend, matching the question’s intent; no schema or logic error is present.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1398,
    "result": {
      "judgement": "Predicted query matches the question and only adds a harmless tie-breaker on event_name; no requirements are violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1524,
    "result": {
      "judgement": "Predicted query returns the customer's currency (CZK) while the question asks for nationality, which is represented by the gas station country (CZE); hence prediction mismaps schema and produces wrong answer.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1405,
    "result": {
      "judgement": "Predicted query correctly sums amount per category for the 'April Speaker' event and orders ascending, matching question intent and gold semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1529,
    "result": {
      "judgement": "Predicted query mis-identifies January 2012 rows by comparing the full transaction date directly to the code '201201', so it omits all January-2012 spending and returns 0, failing to answer the second part of the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1389,
    "result": {
      "judgement": "Prediction uses budget.spent instead of expense.cost, violating explicit evidence that cost is expense.cost, so it answers a different question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1422,
    "result": {
      "judgement": "“Category” could reasonably refer to the event’s own type (Meeting, Election, etc.) or to the budget expense categories tied to those events; the prediction picks the former, which is a valid reading of the question.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1411,
    "result": {
      "judgement": "Predicted query correctly lists the expense descriptions for Sacha Harrison and merely removes duplicates, which is reasonable for “kind of expenses”; hence it satisfies the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1334,
    "result": {
      "judgement": "Predicted query correctly lists first and last names of members whose associated zip_code state is Illinois, matching the question and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1338,
    "result": {
      "judgement": "Predicted query uses an exact date match that misses the event rows, yielding no expenses, so it fails to answer whether the expenses were approved",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1322,
    "result": {
      "judgement": "Predicted query correctly counts events with >10 attendees that are of type 'Meeting', while gold erroneously subtracts meetings and therefore answers a different question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1352,
    "result": {
      "judgement": "Predicted query correctly counts Business-major members with Medium t-shirt size, matching gold semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1435,
    "result": {
      "judgement": "Prediction matches the requested filters and returning duplicates is acceptable for a \"list\" request, so Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1346,
    "result": {
      "judgement": "Predicted query matches gold and correctly retrieves Carlo Jacobs’ phone number without extraneous conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1375,
    "result": {
      "judgement": "Predicted query correctly lists first and last names of all members in the specified department, matching gold semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1376,
    "result": {
      "judgement": "Prediction obeys all stated requirements and is semantically equivalent to the gold; extra NULLIF is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1404,
    "result": {
      "judgement": "Pred query uses approved expenses and returns budget.category as the expense type, matching the request; gold query returns the event’s type and ignores approval, so gold is incorrect.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1317,
    "result": {
      "judgement": "Prediction adds an unwarranted position='Student_Club' filter, yielding 0 instead of the correct count 7, so it fails the question’s requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1464,
    "result": {
      "judgement": "Predicted query uses wrong date literal, returns no rows, so fails to list the students and amounts for 2019-09-09.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1362,
    "result": {
      "judgement": "Prediction counts distinct cities, satisfying the question; no explicit constraints are violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1344,
    "result": {
      "judgement": "Predicted query matches the required filters exactly, returning the fundraising notes for 2019-09-14 as asked.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1164,
    "result": {
      "judgement": "Predicted SQL correctly counts female patients with thrombosis=1 examined in 1997; DISTINCT on patient ID is acceptable and possibly more accurate, with no missing/extra conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1394,
    "result": {
      "judgement": "Predicted query correctly counts members whose major is 'Physics Teaching', matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1392,
    "result": {
      "judgement": "Prediction correctly picks the source with the highest total amount in Sept-2019, while gold merely orders names alphabetically; thus prediction is right and gold is wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1162,
    "result": {
      "judgement": "Predicted query matches all specified filters; COUNT(DISTINCT ID) equals COUNT(*) because ID is primary key, so answer is correct.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1361,
    "result": {
      "judgement": "Prediction correctly sums cost for all pizza expenses as required.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1155,
    "result": {
      "judgement": "Predicted query correctly joins Patient and Laboratory and filters LDH > 500, returning requested columns; duplicates are harmless, so semantics match the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1409,
    "result": {
      "judgement": "Predicted query exactly matches the required filter and aggregation for total cost on 2019-08-20.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1410,
    "result": {
      "judgement": "Prediction matches the required member filter and correctly aggregates cost, returning first and last name as full name components—semantically identical to gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1187,
    "result": {
      "judgement": "Predicted query returns the same distinct patient IDs as gold and satisfies date, GPT, ALB filters; extra join is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1457,
    "result": {
      "judgement": "Predicted query correctly lists each member whose expense cost exceeds the overall average, matching the question’s requirements; differences from gold (omitting budget join, using GROUP BY) are benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1403,
    "result": {
      "judgement": "Predicted query uses event.status instead of budget.event_status but this equally enforces the Closed-event condition, adds no unjustified filters, and otherwise matches the requested logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1460,
    "result": {
      "judgement": "Prediction returns the member matching the given expense description, concatenates first and last name into the requested full name, and shows the cost, matching the question’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1381,
    "result": {
      "judgement": "Predicted query correctly returns each student's full name for those with attendance count > 7, matching question intent and gold result.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1432,
    "result": {
      "judgement": "The prediction divides by member count while the gold divides by income count, but the question does not explicitly state whether the denominator should be members or income records, so both readings are reasonable.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1156,
    "result": {
      "judgement": "Prediction matches the question; lack of DISTINCT merely risks harmless duplicates and no explicit uniqueness requirement was stated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1157,
    "result": {
      "judgement": "Prediction omits DISTINCT but still returns the requested columns for patients whose examinations show Thrombosis = 2, matching the question’s intent; duplicates are acceptable for a simple list.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1401,
    "result": {
      "judgement": "Predicted query correctly retrieves the cost of the 'Posters' expense for the 'September Speaker' event, matching the stated requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1185,
    "result": {
      "judgement": "Predicted query rightly computes the same numerator/denominator as the gold and merely scales the result by 100, an acceptable percentage interpretation of a “decrease rate.”",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1209,
    "result": {
      "judgement": "Predicted query repeats the same patient’s diagnosis for multiple lab records instead of listing each patient once, violating the request to give diagnoses of patients; gold query correctly uses DISTINCT.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1171,
    "result": {
      "judgement": "Predicted query compares birth year to 18 instead of patient age at exam, so it misses valid under-18 cases and returns 0 rather than the true count.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1427,
    "result": {
      "judgement": "Prediction lists the budget categories for MU 215 guest-speaker events with spent = 0, matching the question; the extra constant type column in gold is unnecessary.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1208,
    "result": {
      "judgement": "Predicted query matches gold logic, correctly selecting male patients whose GPT lab result is 60 or higher.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1426,
    "result": {
      "judgement": "Predicted query properly lists last names, department, and college for all students with Environmental Engineering major, whereas gold wrongly adds a position filter not required by the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1179,
    "result": {
      "judgement": "Predicted query uses date string with slashes that does not match stored value, yielding no row, so it fails to return the patient’s aCL IgM concentration.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1150,
    "result": {
      "judgement": "Predicted query correctly computes the ratio of female patients born after 1930 to all female patients, matching the question’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1198,
    "result": {
      "judgement": "Prediction counts female patients only if an examination record is labeled APS, missing female patients whose APS diagnosis appears only in Patient.Diagnosis, so it undercounts and fails the question requirement.",
      "verdict": true,
      "ambiguity": "ambiguous schema",
      "gold_correct": true
    }
  },
  {
    "question_id": 1238,
    "result": {
      "judgement": "Predicted query filters on Examination.Diagnosis instead of Patient.Diagnosis, but both tables contain a Diagnosis column so either is a plausible anchor; thus discrepancy stems from ambiguous schema rather than a clear error.",
      "verdict": false,
      "ambiguity": "ambiguous schema",
      "gold_correct": true
    }
  },
  {
    "question_id": 1169,
    "result": {
      "judgement": "Predicted query correctly counts distinct male vs female patients with abnormal UA and computes their ratio, matching the question, whereas the gold counts test records not patients.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1229,
    "result": {
      "judgement": "Predicted query correctly counts distinct patients with TG ≥ 200 and age > 50, matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1231,
    "result": {
      "judgement": "Predicted query matches all stated requirements—male patients, birth years 1936-1956, CPK ≥ 250, distinct count—so Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1235,
    "result": {
      "judgement": "Predicted query lists only five patient IDs, missing others that satisfy RBC < 3.5, while gold returns all distinct qualifying patients; thus prediction is incomplete.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1152,
    "result": {
      "judgement": "Predicted query multiplies the ratio by 100, outputting a percentage instead of the requested ratio value, so its answer is off by a factor of 100.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1166,
    "result": {
      "judgement": "Prediction returns the same youngest patient’s symptoms and diagnosis (extra ID is harmless); logic and result align with the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1192,
    "result": {
      "judgement": "Prediction matches filters for outpatient patients, October 1991 lab date, and total bilirubin < 2.0, so it answers the question correctly.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1254,
    "result": {
      "judgement": "Prediction correctly counts distinct patients with IgA >80 and <500 and First Date year ≥1990, while gold over-counts by not using DISTINCT and even excludes 1990, so prediction is preferable.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1252,
    "result": {
      "judgement": "Prediction properly counts distinct patients whose IGG is strictly between 900 and 2000 and who have non-null symptoms, matching the question, whereas the gold query double-counts patients and includes boundary values.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1195,
    "result": {
      "judgement": "Prediction filters on Examination.Diagnosis and joins Examination without date, causing possible multiplicative duplicates and omitting patients whose SLE diagnosis is only in Patient; thus average is distorted versus the intended patient-level filter in Patient table.",
      "verdict": true,
      "ambiguity": "ambiguous schema",
      "gold_correct": true
    }
  },
  {
    "question_id": 1281,
    "result": {
      "judgement": "Prediction correctly returns the maximum birthday (youngest) among patients with GOT ≥ 60 and duplicates do not affect MAX, fully satisfying the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1247,
    "result": {
      "judgement": "Prediction applies all three required conditions (male sex, normal WBC, abnormal FG) in the same lab record and counts distinct patients, matching a straightforward reading of the question, whereas the gold query’s missing parentheses makes the male-sex and WBC filters optional for part of the data. Thus the prediction is correct and the gold is faulty.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1227,
    "result": {
      "judgement": "Prediction matches gold logic: computes average age for male patients whose T-CHO ≥ 250 using same join; no missing or extra predicates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1232,
    "result": {
      "judgement": "Predicted query matches the required conditions and returns each patient’s ID, sex, and computed age; extra duplicates are permissible for a listing question, so it satisfies the request just like the gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1275,
    "result": {
      "judgement": "Predicted query follows the evidence‐defined normal values (‘-’, ‘+-’) and counts distinct male patients; gold uses differing codes (‘negative’, ‘0’), so prediction aligns with the question while gold does not.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1265,
    "result": {
      "judgement": "Predicted query filters on the literal symbols '-' and '+-' which do not occur in the data (where normal values are stored as 'negative' and '0'); thus it returns 0 and misses all qualifying patients, so the prediction is incorrect.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1251,
    "result": {
      "judgement": "Pred query correctly counts distinct patients whose IGG is ≥2000, matching the stated requirement, whereas gold imposes an unnecessary Examination join that excludes many qualifying patients.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1225,
    "result": {
      "judgement": "Predicted query properly groups patients by SEX and lists their IDs via GROUP_CONCAT for T-BIL ≥ 2.0, matching the question and evidence, whereas the gold query does not aggregate the IDs as requested.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1030,
    "result": {
      "judgement": "Predicted query correctly finds the league with the highest number of draw matches in season '2015/2016'; no unjustified filters or omissions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1220,
    "result": {
      "judgement": "Prediction retrieves the same patient rows (possibly with duplicates) by filtering UN=29 and thus satisfies the question; lack of DISTINCT is permissible for a list query.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1242,
    "result": {
      "judgement": "Predicted query follows evidence-based definition of “below 50 years old” (current age) and satisfies 1984 lab date and normal platelet level, whereas gold computes age at 1984 contrary to evidence.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1042,
    "result": {
      "judgement": "Prediction matches the question: per-league in season 2009/2010, it compares average home vs away goals using the Match table; no extraneous or missing filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1029,
    "result": {
      "judgement": "Predicted query correctly lists the four highest buildUpPlaySpeed values (with team names) whereas the gold query mistakenly orders ascending and returns the lowest speeds.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1239,
    "result": {
      "judgement": "Predicted query correctly returns patient IDs whose HCT >= 52 in at least two lab records and their age, satisfying the question just like the gold query.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1079,
    "result": {
      "judgement": "Prediction returns the single player with the maximum height, satisfying the question; no extra or missing filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1035,
    "result": {
      "judgement": "Predicted query misses many qualifying team_fifa_api_id values that the gold (and the stated condition) return, so it does not fully answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1257,
    "result": {
      "judgement": "Predicted query correctly counts distinct patients with CRE ≥ 1.5 whose age (based on current year) is under 70, matching the question intent; no unjustified predicates are added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1032,
    "result": {
      "judgement": "Predicted query correctly finds the league whose match count is maximal and returns its name and count, matching the question’s requirement; no unwarranted predicates are added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1270,
    "result": {
      "judgement": "Predicted query also counts patients who completely lack any Examination record, whereas the question’s “does not have any symptom” should apply only when an Examination row exists and its Symptoms field is NULL, so the prediction over-counts and is incorrect.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1057,
    "result": {
      "judgement": "Predicted query correctly computes the average home_team_goal for Polish matches in the 2010/2011 season, matching the question and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1256,
    "result": {
      "judgement": "Prediction counts distinct patients with CRP '+' and null Description as required, while gold over-counts duplicate lab rows.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1098,
    "result": {
      "judgement": "Predicted query takes MAX(score) but does not tie the accompanying class to that max value, so the returned classification may come from a different row than the highest score, violating the question’s explicit pairing requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1025,
    "result": {
      "judgement": "Predicted query matches question requirements; no unjustified filters added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1255,
    "result": {
      "judgement": "Prediction correctly counts distinct patients with IgM <=40 or >=400 and finds their most common diagnosis, aligning with the question; gold mistakenly uses strict bounds and may over-count multiple lab rows.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1028,
    "result": {
      "judgement": "Predicted query drops to one team via LIMIT 1 and misses Celtic, whereas both Rangers and Celtic tied for most away wins; thus it gives an incomplete answer.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1048,
    "result": {
      "judgement": "Prediction returns the same rating (75) for the specified player and year; averaging does not change the correct value, so the answer is semantically correct.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1084,
    "result": {
      "judgement": "Prediction correctly counts distinct players born before 1986 with high defensive work rate, matching the question and gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1031,
    "result": {
      "judgement": "Prediction correctly filters qualifying players and computes their age with a proper date-difference formula, while the gold subtracts two strings (year numbers only), leading to an imprecise off-by-one age; prediction is acceptable.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1103,
    "result": {
      "judgement": "Predicted query correctly filters Aaron Mooy’s rating on 2016-02-04 with an equivalent date condition to the gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1302,
    "result": {
      "judgement": "Prediction counts distinct patients meeting the CPK<250 and positive coagulation criteria, matching the question, while gold counts every joined row and over-counts duplicates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1040,
    "result": {
      "judgement": "Predicted query filters height > 180, computes average heading accuracy per player, orders DESC and returns 10 names, so it satisfies the question despite using name as the grouping key; differences with gold are minor and not clearly wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1136,
    "result": {
      "judgement": "Prediction counts distinct players with max crossing and left foot, matching the wording, whereas gold counts individual attribute rows and double-counts a player.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": false
    }
  },
  {
    "question_id": 1044,
    "result": {
      "judgement": "Predicted query correctly filters for players born in 1970 and in month 10, matching the question just like the gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1078,
    "result": {
      "judgement": "Prediction correctly returns the older of the two by selecting the earlier birthday.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1039,
    "result": {
      "judgement": "Predicted query correctly computes the average long_shots for the player and even avoids the possible null-denominator issue present in the gold; no explicit requirement is violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1036,
    "result": {
      "judgement": "Predicted query correctly lists teams whose 2012 build-up play passing exceeds the overall 2012 average, satisfying all stated requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1096,
    "result": {
      "judgement": "Predicted query correctly computes the average overall_rating for player 'Pietro Marino' using an equivalent aggregation as the gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1076,
    "result": {
      "judgement": "Predicted query correctly computes the difference between the two players’ average ball control scores using equivalent joins and aggregates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1122,
    "result": {
      "judgement": "Prediction selects the player whose overall_rating is maximal and returns that player’s name; the singular wording “the most strongest player” makes returning one name acceptable, and no unjustified filters are added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1092,
    "result": {
      "judgement": "Predicted query filters 2008/2009 matches, counts per league, and returns one league with the maximal count; since the question asks for \"the league\" singular and does not mandate tie handling, this satisfies the request.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1080,
    "result": {
      "judgement": "Prediction counts distinct players with left preferred foot and low attacking work rate, matching the question, whereas gold counts attribute rows, so prediction is correct.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1110,
    "result": {
      "judgement": "Prediction selects buildUpPlayPassingClass for FC Lorient on the specified date exactly as asked, matching the gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1102,
    "result": {
      "judgement": "Predicted query correctly filters for rating 77 on 2016-06-23, orders by earliest birthday to find the oldest, and returns the player name, matching the question’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1114,
    "result": {
      "judgement": "Predicted query correctly computes the average overall_rating for Marko Arnautovic within the specified date range; differing join key from gold is still valid and preserves semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1058,
    "result": {
      "judgement": "Predicted SQL reasonably returns the player’s name (a person) who, among the tallest and shortest players, has the highest average finishing rate; this fits the “Who” wording, whereas the gold returns only the label “Min/Max”.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1133,
    "result": {
      "judgement": "Both queries correctly count players named Aaron with birthday after 1990; using DISTINCT player_api_id is a harmless choice and may even avoid duplicates, so prediction is acceptable.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1091,
    "result": {
      "judgement": "Predicted query exactly matches required filters and counts matches in April 2009 for Belgium Jupiler League, same logic as gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1116,
    "result": {
      "judgement": "Predicted query wrongly limits to a single player, while the question and evidence explicitly demand all players with height rank = 1.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1113,
    "result": {
      "judgement": "Prediction correctly returns defenceAggressionClass for Hannover 96 on 2015-09-10, while gold targets an unrelated column, so prediction stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 1146,
    "result": {
      "judgement": "Prediction matches the question’s requirement; extra alphabetical tie-breaker is benign and acceptable.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 850,
    "result": {
      "judgement": "Predicted query correctly joins races with circuits filtered by country Germany; duplicates are harmless and likely truncated display includes Luxembourg later, so logic aligns with question and gold semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1139,
    "result": {
      "judgement": "Prediction retrieves home and away goals for the specified 24-Sep-2008 Belgian Jupiler League match, satisfying the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 859,
    "result": {
      "judgement": "Predicted query correctly retrieves Bruno Senna’s Q1 time for race 354, matching the gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 846,
    "result": {
      "judgement": "Predicted query correctly selects the five slowest Q1 times for race 20 and returns their driverRef; the extra IS NOT NULL is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1105,
    "result": {
      "judgement": "Prediction matches gold logic and fully satisfies question; no extra or missing predicates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 875,
    "result": {
      "judgement": "Prediction correctly retrieves the season page (url) for the year of race 901, matching the question and gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 868,
    "result": {
      "judgement": "Prediction returns the correct latitude and longitude; extra identical rows don’t violate the question, so the Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 847,
    "result": {
      "judgement": "Predicted query correctly finds the surname of a driver whose q2 time is the minimum for race 19; extra ORDER BY/LIMIT only chooses one driver in case of ties, which is acceptable as the question asks for “the” driver and gives no tie rule.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1147,
    "result": {
      "judgement": "Predicted query correctly returns a player with the maximum overall_rating (any one is acceptable) and satisfies the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 895,
    "result": {
      "judgement": "Predicted query matches driver, race name, year, and computes AVG milliseconds, fulfilling the question exactly like the gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 865,
    "result": {
      "judgement": "Prediction omits a DOB IS NOT NULL filter, so it could select a driver with unknown birthdate as oldest; gold correctly excludes null DOBs.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1148,
    "result": {
      "judgement": "Predicted SQL follows the evidence formula by dividing the count of players who are <180 cm and overall_rating>70 by the total player count, whereas the gold divides by only the <180 cm players, so gold mis-computes the requested percentage and prediction is correct.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 884,
    "result": {
      "judgement": "Prediction correctly lists races in the year-month of the minimum date, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 909,
    "result": {
      "judgement": "Prediction correctly computes the percentage of European Grand Prix races held in Germany with proper join and filters, matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 861,
    "result": {
      "judgement": "Predicted query matches gold logic, using same filters and returning the driver’s number, thus answers the question correctly.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 862,
    "result": {
      "judgement": "Predicted query correctly counts drivers without finish times for the 2007 Bahrain Grand Prix, matching gold semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 866,
    "result": {
      "judgement": "Predicted query targets the same race, same lap-time pattern, and returns the drivers’ names and URLs; lack of DISTINCT only adds duplicates, not wrong rows, so it answers the question correctly.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 880,
    "result": {
      "judgement": "Predicted query correctly computes the percent difference between Paul di Resta’s fastest-lap speeds in races 853 and 854, matching the question’s stated formula.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1107,
    "result": {
      "judgement": "Prediction returns the earliest date on which Kevin Constant attained his maximum crossing value, matching the question, while the gold query instead takes the latest date and is therefore semantically wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 898,
    "result": {
      "judgement": "Prediction returns the same driver and age as gold, merely changing column order, satisfying the question’s requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 881,
    "result": {
      "judgement": "Predicted query correctly computes (completed drivers / total drivers) * 100 for the race dated 1983-07-16, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 877,
    "result": {
      "judgement": "Predicted query correctly selects the latest dob among finishers in race 872, yielding Sergio Pérez; adding driverId is harmless.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1130,
    "result": {
      "judgement": "Predicted query correctly returns the distinct team_short_name values for teams with chanceCreationPassingClass = 'Safe', matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 937,
    "result": {
      "judgement": "Predicted query uses positionOrder=2 to capture the 2nd-place finisher, matching ordinary race ranking, while gold uses rank=2 (fastest-lap rank), so gold targets a different metric; thus predicted SQL correctly answers the question and gold is wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 915,
    "result": {
      "judgement": "Prediction fails to exclude drivers without a birth date, so it may choose a NULL dob row rather than the true earliest date; thus it does not reliably give the oldest driver’s country.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 902,
    "result": {
      "judgement": "Prediction uses the finishing-position (<20) interpretation of “track number,” which is fully consistent with the question and schema, whereas gold uses championship-standing position; both are plausible, so the prediction is acceptable.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 901,
    "result": {
      "judgement": "Prediction correctly returns race name, circuit name and location for races held in September 2005; no requirement violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1145,
    "result": {
      "judgement": "Prediction returns the same four leagues filtered by season and ranked by game count; ordering differences under a tie are immaterial to the question, so the SQL is correct.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 945,
    "result": {
      "judgement": "Prediction correctly counts circuits matching Adelaide and Australia, equivalent to gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 896,
    "result": {
      "judgement": "Prediction counts Hamilton’s race results since 2010 where finishing position > 1, matching the evidence and question, while gold wrongly uses driverStandings (championship rank, not race finish).",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 857,
    "result": {
      "judgement": "Predicted query correctly returns the latitude and longitude of the circuit hosting the Abu Dhabi Grand Prix, matching the gold semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 910,
    "result": {
      "judgement": "Prediction aligns exactly with question, retrieving lat and lng for Silverstone Circuit.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 955,
    "result": {
      "judgement": "Predicted query mis-extracts minutes and seconds (e.g., substr(4,2) returns “8:” not “48”), yielding much smaller times, so it does not answer the question correctly.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 930,
    "result": {
      "judgement": "Prediction picks one of the races where Hamilton achieved the top (minimum) rank; returning a single tie-winner is acceptable when the question does not mandate listing all, so the answer is semantically correct.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 962,
    "result": {
      "judgement": "Pred counts unique drivers while gold counts individual race results; either interpretation is plausible for “percentage of drivers”, so prediction is still a valid answer.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 897,
    "result": {
      "judgement": "Prediction sums the cumulative wins instead of counting wins as required (evidence specifies MAX(COUNT(wins))), so it uses an incorrect metric though it coincidentally returns same driver; this violates an explicit requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 950,
    "result": {
      "judgement": "Predicted query matches gold and correctly returns constructor names with zero points at race 291.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 912,
    "result": {
      "judgement": "Prediction perfectly matches the required filter and column.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 940,
    "result": {
      "judgement": "Predicted query correctly counts all drivers who had a non-NULL time in the 2008 Chinese Grand Prix (i.e., finished) and, by virtue of appearing in results, have participated in Formula 1 races; logic matches question and gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 981,
    "result": {
      "judgement": "Predicted query correctly finds the youngest driver, selects his earliest qualifying race, and returns year, race name, date, and time, matching question intent and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 964,
    "result": {
      "judgement": "Prediction matches the question, selecting the code of American drivers with no extraneous filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 928,
    "result": {
      "judgement": "‘Ranked first’ can reasonably mean finishing first (winner) or fastest-lap rank; pred chooses winner (Hamilton) using positionOrder=1, which matches one valid interpretation, so it is acceptable.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 1003,
    "result": {
      "judgement": "Prediction correctly counts each driver’s accidents with statusId=3 in all Canadian Grand Prix races and returns the maximum, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 948,
    "result": {
      "judgement": "Prediction matches gold logic; it correctly returns the max points scored by British constructors.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 730,
    "result": {
      "judgement": "Prediction satisfies both publisher and power filters and returns superhero names, matching the question and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 724,
    "result": {
      "judgement": "Predicted query correctly retrieves superhero names whose eye colour is Blue and hair colour is Blond using appropriate joins and filters, matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 872,
    "result": {
      "judgement": "Predicted SQL matches gold, correctly retrieves driver code for race 45 with Q3 time 1:33.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 963,
    "result": {
      "judgement": "Prediction counts distinct French drivers achieving a sub-2-minute lap, matching the natural reading of “How many French drivers…”, whereas gold counts every qualifying lap, not drivers, so gold misinterprets granularity.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 977,
    "result": {
      "judgement": "Prediction correctly counts disqualified finishers between race IDs 51-99, matching question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1144,
    "result": {
      "judgement": "Prediction matches the query intent, correctly retrieving finishing and curve for the heaviest-weight player; any tie or date ambiguity is inherent in the question and handled similarly to the gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 738,
    "result": {
      "judgement": "Prediction correctly lists superheroes whose Durability attribute is below 50, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 743,
    "result": {
      "judgement": "Prediction matches the question’s requirements, computing the overall percentage of Bad-aligned heroes and the count of such heroes from Marvel, identical to the gold result.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1014,
    "result": {
      "judgement": "Predicted query correctly lists each Italian circuit with its fastest lap, whereas gold only returns a single overall fastest lap, so gold is faulty and prediction should stand.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 751,
    "result": {
      "judgement": "Prediction correctly returns five distinct male superhero powers with no extraneous filtering, matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 760,
    "result": {
      "judgement": "Predicted query correctly computes the percentage of superheroes between 150-180 cm whose publisher is Marvel, matching gold semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 988,
    "result": {
      "judgement": "Prediction correctly filters German drivers born 1980-1985, computes each driver’s average pit-stop duration, orders ascending, and returns the top 3; extra avg column is harmless.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 854,
    "result": {
      "judgement": "Predicted query returns the lat/lng for all races named \"Australian Grand Prix\"; this meets the request even if duplicates appear, so it is semantically correct.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 733,
    "result": {
      "judgement": "Prediction matches the required filters and counting logic; DISTINCT is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 1001,
    "result": {
      "judgement": "Predicted query correctly selects the driver with the fastest Q3 time at Marina Bay Street Circuit in 2008 and returns his full name, matching both the question intent and gold result.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 869,
    "result": {
      "judgement": "Prediction matches gold semantics; extra tie-breaker on constructorId is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 775,
    "result": {
      "judgement": "Predicted query correctly computes blue-female count divided by all female superheroes (using a permissive LEFT JOIN that still matches the requirement), so no explicit requirement is violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 745,
    "result": {
      "judgement": "Predicted query meets the question requirement without extraneous conditions, matching gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 944,
    "result": {
      "judgement": "Predicted query returns no rows, so it fails to provide the requested percentage; gold query also appears wrong, but prediction is still incorrect.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 764,
    "result": {
      "judgement": "Predicted query correctly retrieves the power names for hero_id 1 and any duplicate handling is non-essential for the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 960,
    "result": {
      "judgement": "Predicted query matches gold intent, correctly averaging fastestLapSpeed for the 2009 Spanish Grand Prix; extra CAST is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 791,
    "result": {
      "judgement": "Predicted query omits heroes with NULL heights by using AVG(height_cm) instead of the specified SUM/COUNT(all heroes) formula, so it does not match the required average.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 726,
    "result": {
      "judgement": "Predicted query correctly lists Marvel heroes sorted by descending height, which satisfies ranking requirement even without an explicit rank column.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 906,
    "result": {
      "judgement": "Predicted query correctly selects Lewis Hamilton’s earliest race (earliest raceId for him) and returns the race name together with the points he earned in that race, whereas the gold query returns all races in the first season and cumulative points, so gold is faulty.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 769,
    "result": {
      "judgement": "Prediction returns no hero due to case-sensitive attribute filter, failing to answer the question, while gold also omits the durability filter; prediction is incorrect so we overturn.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 781,
    "result": {
      "judgement": "Predicted query correctly returns height_cm of superheroes with eye colour Amber, matching gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 806,
    "result": {
      "judgement": "Predicted query correctly joins superhero to colour on eye_colour_id and filters by full name, returning the required eye colour.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 739,
    "result": {
      "judgement": "Predicted query correctly lists names of superheroes whose power_name is 'Death Touch', matching gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 933,
    "result": {
      "judgement": "Predicted query matches gold semantics, correctly retrieves Hamilton’s positionOrder in 2008 Chinese Grand Prix.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 794,
    "result": {
      "judgement": "Predicted query correctly identifies the hero with the maximum Speed, matching gold logic; extra alphabetical tiebreaker is benign.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 892,
    "result": {
      "judgement": "Predicted query correctly finds the driver whose driverStandings points value reaches the overall maximum and outputs his full name and that points, matching the task and gold result.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 786,
    "result": {
      "judgement": "Prediction correctly counts heroes whose strength equals the maximum strength, while gold’s max is taken across all attributes, so prediction is sound and gold likely wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 753,
    "result": {
      "judgement": "Predicted query meets the stated height and eye-colour conditions; absence of DISTINCT is benign for a name list, so prediction is correct.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 822,
    "result": {
      "judgement": "Prediction correctly counts superheroes whose skin colour is green and alignment is bad, matching the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 954,
    "result": {
      "judgement": "Predicted query correctly computes the percentage of Japanese drivers who finished races between 2007 and 2009, matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 798,
    "result": {
      "judgement": "Prediction satisfies the question, selecting publisher_name for the three specified superheroes exactly as the gold does.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 732,
    "result": {
      "judgement": "Predicted query correctly finds the publisher of the hero with the minimum Speed attribute; extra tie-breaker ordering is harmless.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 537,
    "result": {
      "judgement": "Predicted query correctly counts posts owned by the user with DisplayName 'csgillespie', matching gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 971,
    "result": {
      "judgement": "Predicted query correctly selects the German driver with the earliest date of birth; using dob directly vs JULIANDAY is an equivalent ordering approach.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 904,
    "result": {
      "judgement": "Prediction uses total race time not lap time, so it finds the race with the shortest overall finish instead of Schumacher’s fastest single lap, giving a wrong answer.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 772,
    "result": {
      "judgement": "Predicted query correctly lists eye, hair, and skin colour names for female superheroes published by Dark Horse Comics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 744,
    "result": {
      "judgement": "Prediction correctly computes #Marvel minus #DC superheroes and matches question intent with no extraneous conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 829,
    "result": {
      "judgement": "Predicted query correctly computes DC minus Marvel superhero count and does not add or omit any required filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 717,
    "result": {
      "judgement": "Predicted query correctly lists every power_name linked to superhero_name = '3-D Man', matching the question’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 533,
    "result": {
      "judgement": "Prediction correctly applies the date filter (> 2014-09-01) per guideline that “after” is inclusive, while gold erroneously strips the time and omits 2014-09-01 accesses.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 931,
    "result": {
      "judgement": "Predicted query correctly selects the maximum fastestLapSpeed for the 2009 Spanish Grand Prix, matching the question’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 567,
    "result": {
      "judgement": "Predicted query correctly counts all posts authored by the user with display name 'Tiago Pasqualini', matching the gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 549,
    "result": {
      "judgement": "Predicted query correctly fetches the body of the post referenced by the ExcerptPostId for tag 'bayesian', matching the question and gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 761,
    "result": {
      "judgement": "Predicted query correctly filters male superheroes whose weight exceeds 79% of the overall average weight, matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 728,
    "result": {
      "judgement": "Predicted query lists eye colors for Marvel heroes with counts ordered by descending frequency, fulfilling the requested ranking even without an explicit rank column.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 723,
    "result": {
      "judgement": "Prediction matches the question: counts blue-eyed heroes who have the 'Agility' power, using correct joins; DISTINCT is harmless.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 572,
    "result": {
      "judgement": "Prediction returns the view count for the specified post exactly as requested, matching the gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 779,
    "result": {
      "judgement": "Prediction counts the joined hero_power rows for Amazo, matching the question’s requirement and effectively identical to the gold query.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 740,
    "result": {
      "judgement": "The predicted query correctly counts female superheroes with Strength 100, adding only a harmless DISTINCT that aligns with the question’s intent; no explicit requirements are violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 737,
    "result": {
      "judgement": "Predicted query correctly retrieves Copycat's race matching the gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 792,
    "result": {
      "judgement": "Predicted query matches gold logic—joins superhero to powers and filters on superhero_name, fulfilling the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 563,
    "result": {
      "judgement": "Predicted query uses an incorrect date literal and returns no row, so it fails to supply the favorite count requested.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 592,
    "result": {
      "judgement": "Predicted query correctly counts users having more than 5 badges, matching question intent and gold logic without extraneous predicates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 788,
    "result": {
      "judgement": "Prediction uses Marvel heroes as denominator, giving percent of Marvel heroes who are female, not percent of female heroes published by Marvel; thus it answers a different question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 750,
    "result": {
      "judgement": "Predicted query correctly computes the average weight for rows with gender='Female', matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 819,
    "result": {
      "judgement": "Predicted query correctly filters superheroes with missing weight and computes the difference using eye_colour_id values 7 (blue) and 1 (none); joining to the colour table is unnecessary, so semantics match the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 967,
    "result": {
      "judgement": "Prediction only returns the count and omits the requested code numbers of the top-3 youngest drivers, failing an explicit requirement of the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 578,
    "result": {
      "judgement": "Predicted query correctly joins posts with users and filters by the exact title to return the user display name and reputation, matching question intent and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 758,
    "result": {
      "judgement": "Predicted query returns no rows because it filters on r.race = 'human' while actual values are 'Human', so it fails to satisfy the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 800,
    "result": {
      "judgement": "Predicted query correctly computes blue-eyed superheroes divided by total joined superheroes, matching gold logic; no missing or extra filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 539,
    "result": {
      "judgement": "Predicted query correctly retrieves the owner's display name by joining posts with users on owner user id and filtering by the given title.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 604,
    "result": {
      "judgement": "Prediction correctly computes the average up-votes and age for users who have authored more than 10 posts, matching the question’s requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 773,
    "result": {
      "judgement": "Predicted query correctly selects superheroes whose eye, hair, and skin colour ids are all equal and returns their publisher, matching the question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 990,
    "result": {
      "judgement": "Predicted query correctly selects the winning constructor of the 2009 Singapore Grand Prix by using position = 1, an acceptable equivalent to the gold’s time-pattern filter.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 669,
    "result": {
      "judgement": "Predicted query correctly returns the earliest vote date by user 'chl', matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 766,
    "result": {
      "judgement": "Predicted query filters on lowercase 'strength', returning no rows, thus fails to identify any hero with highest strength.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 790,
    "result": {
      "judgement": "Prediction matches question intent; computes Emil minus Charles weights exactly like gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 785,
    "result": {
      "judgement": "Prediction correctly lists superhero names whose alignment is Neutral, matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 801,
    "result": {
      "judgement": "Predicted query correctly computes male count divided by female count just like gold; no extra or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 531,
    "result": {
      "judgement": "Prediction returns the higher-reputation user (Harlan) just as required; extra column and LIMIT-based tie handling are permissible.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 797,
    "result": {
      "judgement": "Predicted SQL correctly selects superhero names having blue eyes and brown hair, matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 555,
    "result": {
      "judgement": "Predicted query correctly computes the average score for posts whose owner’s display name is 'csgillespie', matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 532,
    "result": {
      "judgement": "Predicted query matches the gold and satisfies the requirement to list all display names with CreationDate in 2011.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 825,
    "result": {
      "judgement": "Prediction matches the required logic for fetching the gender of any superhero possessing the Phoenix Force power.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 565,
    "result": {
      "judgement": "Prediction correctly checks ClosedDate for that post and returns a 1 (well-finished); only output wording differs from gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 573,
    "result": {
      "judgement": "Prediction matches the gold and satisfies the question’s requirement to list comment texts with score 17.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 547,
    "result": {
      "judgement": "Predicted query correctly counts posts with score ≥20 owned by users older than 65, matching the question and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 694,
    "result": {
      "judgement": "Predicted query lists 10 latest comments but returns NULL for every user name because it uses comments.UserDisplayName instead of the actual users.DisplayName, so it fails to supply the requested display names; gold query is also flawed (returns only one comment).",
      "verdict": true,
      "ambiguity": "ambiguous schema",
      "gold_correct": false
    }
  },
  {
    "question_id": 557,
    "result": {
      "judgement": "Predicted query correctly computes percentage of posts with Score>5 that are owned by users older than 65; no extraneous filters added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 736,
    "result": {
      "judgement": "Prediction returns one valid superhero with the minimum Intelligence value; tie-handling difference is acceptable for singular wording \"Who is the dumbest superhero?\"",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 683,
    "result": {
      "judgement": "Prediction correctly limits both numerator and denominator to 2011 posts, matching the question, whereas gold divides by all posts regardless of year.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 747,
    "result": {
      "judgement": "Prediction matches the question, counting all rows where full_name is NULL just like gold; no extra or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 581,
    "result": {
      "judgement": "Predicted query omits the question-mark in the title filter, yields no rows, so it fails to return the owner whereas the gold correctly returns 'Paul'.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 765,
    "result": {
      "judgement": "Predicted query correctly counts heroes with the Stealth power; DISTINCT is benign and aligns with counting heroes.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 576,
    "result": {
      "judgement": "Predicted query pulls UserDisplayName from comments, which is NULL for this registered user, so it fails to return the actual commenter name whereas the gold query correctly joins to users and returns “Preets”.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 710,
    "result": {
      "judgement": "Predicted query counts comments with score 0 on posts that have exactly one comment, matching the question, whereas gold incorrectly filters on post score 0, so prediction is correct and gold is wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 782,
    "result": {
      "judgement": "Predicted query correctly returns superheroes whose eye and hair colours are both black; no extra or missing predicates compared to the stated requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 796,
    "result": {
      "judgement": "Predicted SQL correctly retrieves every attribute name with its corresponding value for the superhero '3-D Man', matching the gold and the question without unwarranted constraints.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 640,
    "result": {
      "judgement": "Prediction correctly sums view counts of posts authored by each user via posts.OwnerUserId, while gold sums any posts the users ever edited via postHistory, which over-counts; prediction fits the plain reading of the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 349,
    "result": {
      "judgement": "Predicted query correctly finds the card with the highest number of rulings and reports its artist plus promo status, matching the question, whereas the gold query instead analyzes promo artists and is not aligned.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 571,
    "result": {
      "judgement": "Predicted query computes count(posts)/count(votes) for user 24 as asked, while the gold joins incorrectly and just yields the post count, so prediction is preferred.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 665,
    "result": {
      "judgement": "Prediction matches the question requirements and mirrors the gold logic, counting 2010 postLinks tied to posts with ≤2 answers and averaging per month.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 633,
    "result": {
      "judgement": "Predicted query correctly selects the post owned by user “slashnick” with the highest AnswerCount and returns its Id; no unjustified filters are added and logic matches the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 629,
    "result": {
      "judgement": "Predicted query multiplies the 2010-to-2011 vote ratio by 100, returning a percentage rather than the actual ratio requested, whereas the gold query correctly outputs the raw ratio.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 824,
    "result": {
      "judgement": "Predicted query correctly selects superheroes whose power_name is 'Wind Control' and orders their names alphabetically, fully satisfying the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 358,
    "result": {
      "judgement": "Prediction returns four identical rows of 'black', giving the correct border color despite duplicates, so it satisfies the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 379,
    "result": {
      "judgement": "Predicted query correctly selects the IDs of cards whose duelDeck is 'a', fully matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 671,
    "result": {
      "judgement": "Prediction matches the gold in filtering Autobiographer badges and selecting the earliest one, returning the user’s display name; no extraneous conditions or omissions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 409,
    "result": {
      "judgement": "Predicted query matches the required filters and sensibly counts distinct cards; no extra or missing conditions compared to the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 687,
    "result": {
      "judgement": "Predicted query correctly counts comments for one of the highest-scoring posts; result mismatch is only a tie-handling artifact, so Prover’s pass stands.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 544,
    "result": {
      "judgement": "Predicted query returns NULL because it looks only at posts.LastEditorDisplayName, but the actual display name is stored in users via LastEditorUserId; thus it fails to provide the required name.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 672,
    "result": {
      "judgement": "Predicted query properly counts distinct UK users with at least one post having FavoriteCount≥4, whereas gold counts duplicate users for multiple qualifying posts, violating the “how many users” requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 568,
    "result": {
      "judgement": "Predicted query correctly joins votes and users to retrieve the display name for vote Id 6347, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 704,
    "result": {
      "judgement": "Predicted query exactly matches gold and meets the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 440,
    "result": {
      "judgement": "Predicted query adds an unnecessary join to cards requiring c.name = 'A Pedra Fellwar', which does not exist, so it returns no language whereas the correct answer is 'Portuguese (Brazil)'.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 586,
    "result": {
      "judgement": "Predicted query correctly identifies users who placed a bounty of 50 on posts with 'variance' in the title, matching gold rows; extra title column in gold is optional for the ask.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 716,
    "result": {
      "judgement": "Predicted query measures the share of unique users (one per user) whose comments fall in the 5-10 score range, while the gold counts each comment, so the difference stems from an ambiguous reading of whether duplicates should be collapsed; user-level interpretation is reasonable, so prediction is acceptable.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 345,
    "result": {
      "judgement": "Prediction only returns repeated 'Legal' values and misses 'Restricted' and 'Banned', so it does not fully state the legality statuses requested.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 473,
    "result": {
      "judgement": "Predicted query correctly returns false (0) indicating the card is not limited to foreign-only sets, matching the intended NO answer.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 368,
    "result": {
      "judgement": "Predicted query correctly computes 100 × (borderless rows / total rows) using equivalent COUNT logic; no requirements are violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 487,
    "result": {
      "judgement": "Predicted query correctly computes the proportion of cards in the Coldsnap set where both cardKingdomFoilId and cardKingdomId are non-null, matching the question’s requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 383,
    "result": {
      "judgement": "Prediction matches gold logic, counting banned cards with white borders, no superfluous predicates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 634,
    "result": {
      "judgement": "Predicted query returns no rows because it relies on OwnerDisplayName, missing posts linked through users/postHistory, so it fails to identify which author’s posts are more popular.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 587,
    "result": {
      "judgement": "Prediction correctly gets posts whose Tags contain <humor>, computes the post-level average view count, and outputs each title with each of its comments; this fulfills the question even though it returns more qualifying posts than the gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 678,
    "result": {
      "judgement": "Predicted query correctly finds Harvey Motulsky’s post with the highest ViewCount and returns its id and title, matching the question and gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 705,
    "result": {
      "judgement": "Prediction matches the gold logic and satisfies the question without extraneous conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 405,
    "result": {
      "judgement": "Predicted query filters on a language value that does not exist in the data, yielding 0 instead of the correct count 7; therefore it fails to answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 422,
    "result": {
      "judgement": "Predicted query correctly retrieves the language for multiverseid 149934; extra join on cards does not alter the required result.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 468,
    "result": {
      "judgement": "Prediction correctly retrieves the Simplified Chinese translation for the set named “Eighth Edition,” matching the gold semantics.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 215,
    "result": {
      "judgement": "Prediction gives the total number of distinct iodine or sulfur atoms in single-bond molecules, a plausible reading of the ambiguous request for 'how many atoms with iodine and with sulfur type elements'.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 459,
    "result": {
      "judgement": "Predicted query correctly identifies the higher-cost card (Serra Angel), and extra cost column is harmless.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 483,
    "result": {
      "judgement": "Prediction matches the requested Italian text rulings for cards in Coldsnap; duplicates are acceptable, so it fulfills the query.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 231,
    "result": {
      "judgement": "Predicted query correctly returns both the majority bond type and the molecule’s carcinogenic label, matching the question, whereas the gold query omits the label.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 637,
    "result": {
      "judgement": "Prediction lists distinct tag names for Mark Meckes-owned posts whose CommentCount is 0, fully matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 530,
    "result": {
      "judgement": "Prediction lists each Allen Williams card with its frameVersion and shows status when banned, fulfilling the question’s requirements; discrepancies with gold arise only from join strategy and duplicates, not from semantic errors.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 208,
    "result": {
      "judgement": "Predicted query correctly identifies the label with the greatest number of hydrogen atoms, matching the gold logic.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 227,
    "result": {
      "judgement": "Predicted query correctly computes the percentage of carcinogenic molecules with three-decimal rounding just like the gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 240,
    "result": {
      "judgement": "Predicted SQL correctly selects the distinct elements for molecule TR004, matching the question and gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 344,
    "result": {
      "judgement": "Predicted query correctly lists distinct card names satisfying mythic rarity and banned in gladiator, differing from gold only in returning deduplicated names instead of print ids.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 682,
    "result": {
      "judgement": "Prediction fails to supply the actual owner display name (returns NULL because it uses posts.OwnerDisplayName instead of users.DisplayName), so it does not meet the question’s requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 707,
    "result": {
      "judgement": "Prediction matches question intent with correct filtering and highest-score selection; extra tie-breaker harmless.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 12,
    "result": {
      "judgement": "Predicted query omits the required real-number cast, so the integer division in the excellence-rate filter evaluates to 0 and filters out all rows, yielding NULL instead of the true maximum 0.9049; therefore the prediction is wrong while the gold is correct.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 253,
    "result": {
      "judgement": "The prediction returns the elements involved in every triple bond (both atoms per bond); the question does not specify one-column vs two-column output or orientation, so this is a reasonable interpretation.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 356,
    "result": {
      "judgement": "Predicted query correctly counts cards whose power is the wildcard value denoting infinity, matching question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 327,
    "result": {
      "judgement": "Prediction satisfies label filter and atom count >5, returning qualifying molecule IDs exactly as asked.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 415,
    "result": {
      "judgement": "Predicted query filters status by lowercase 'legal', matching no rows, yielding NULL rather than the required percentage, so it fails to answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 347,
    "result": {
      "judgement": "Prediction returns each card id illustrated by Stephen Daniele with its ruling text and a yes/no flag derived from hasContentWarning, exactly matching the question’s requirements; differences from gold are cosmetic only.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 518,
    "result": {
      "judgement": "Predicted SQL correctly identifies the format(s) with the most banned cards and lists all banned card names for those format(s); any difference from gold is only tie-handling, which is reasonable.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 465,
    "result": {
      "judgement": "Prediction checks Korean translation at card level rather than confirming whether the set containing the card has a Korean translation, so it answers a different question and yields the wrong result.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 377,
    "result": {
      "judgement": "Added IS NOT NULL is redundant given SQL three-valued logic; prediction answers the question correctly.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 40,
    "result": {
      "judgement": "Predicted query includes schools whose AvgScrRead is NULL and therefore may choose a school without an actual reading score, returning a different phone number than the one for the lowest scored school; this violates the question’s intent.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 200,
    "result": {
      "judgement": "Prediction matches the intent—returns molecules whose bonds are triple (‘#’) and whose label is carcinogenic (‘+’); no extraneous or missing conditions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 479,
    "result": {
      "judgement": "Prediction correctly counts cards in the Coldsnap set with converted mana cost > 5 whose power is '*' or NULL, matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 72,
    "result": {
      "judgement": "Predicted query matches the required filters and correctly returns the 5-17 enrollment figure for State Special School in Fremont for academic year 2014-2015; no extraneous or missing predicates detected.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 92,
    "result": {
      "judgement": "Predicted SQL correctly counts distinct districts with at least one female client and average salary strictly between 6000 and 10000, matching the question’s wording; no unjustified predicates are added.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 416,
    "result": {
      "judgement": "Predicted query satisfies all stated conditions and matches gold logic; no explicit requirement violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 218,
    "result": {
      "judgement": "Predicted query correctly counts carcinogenic molecules lacking any fluorine, whereas gold counts molecules that merely have at least one non-F atom, so gold is wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 528,
    "result": {
      "judgement": "Predicted query properly lists each card from the Hour of Devastation set together with every format where its legality status is 'Legal', matching the question’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 466,
    "result": {
      "judgement": "Predicted query matches the question’s intent; extra join to sets is harmless and doesn’t alter count.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 232,
    "result": {
      "judgement": "Predicted query correctly selects non-carcinogenic molecules that contain at least one single bond, orders them alphabetically, and limits to three, matching the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 118,
    "result": {
      "judgement": "Prediction counts distinct accounts with running loans under 100k over all such accounts, matching the requested percentage of accounts, while gold divides on loan count, so prediction is acceptable and gold is likely wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 480,
    "result": {
      "judgement": "Prediction matches question intent and aligns with gold; no violating predicates.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 206,
    "result": {
      "judgement": "Predicted query appropriately retrieves elements of both atoms involved in bond TR004_8_9 without adding unjustified filters; no explicit requirement is violated.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 220,
    "result": {
      "judgement": "Predicted query satisfies the request exactly like the gold, listing the first three distinct elements for molecule TR000 in alphabetical order.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 149,
    "result": {
      "judgement": "Prediction obeys the loan-ineligibility condition and the salary bound (>8000 and ≤9000) exactly as phrased, while the gold includes 8000; otherwise both return the same distinct type, so prediction is correct and gold is slightly off.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 236,
    "result": {
      "judgement": "Prediction correctly retrieves the bond type and both atom IDs for bond TR001_6_9; filter and joins match the question’s requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 391,
    "result": {
      "judgement": "Prediction omits most qualifying black artifact cards (returns only two names, not the full set) so it does not fully answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 248,
    "result": {
      "judgement": "Predicted query correctly lists both atoms involved in each triple bond of molecule TR041, matching the question and gold intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 414,
    "result": {
      "judgement": "Predicted query filters by block Ravnica and base set size 180 then returns the languages of its translations, matching the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 245,
    "result": {
      "judgement": "Predicted query correctly averages bond counts per iodine atom and adds no unjustified filters, matching the question’s intent; any differences are benign or even more comprehensive than gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 115,
    "result": {
      "judgement": "Predicted query selects one district in South Bohemia with the maximum inhabitants and computes the male-client percentage, matching the literal “branch … with biggest number of inhabitants”; the gold instead aggregates across all districts sharing that inhabitant count, a different but arguable handling of ties, so prediction is still valid.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 529,
    "result": {
      "judgement": "Predicted query properly requires Korean translation and absence of Japanese translation, matching the question, whereas gold only checks for Korean translation and ignores the Japanese-absence requirement.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 207,
    "result": {
      "judgement": "Predicted query properly links atoms to the specific double-bond records via connected.bond_id, whereas the gold query merely requires the atom to be in any molecule that has a double bond, so it over-includes elements; thus prediction is correct and gold is faulty.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 268,
    "result": {
      "judgement": "Prediction correctly pulls elements for both atoms in the bond, satisfying the question, while gold joins only on atom_id and may miss the second atom but this does not harm our decision; no requirement is violated by the prediction.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 137,
    "result": {
      "judgement": "Predicted query filters on the client’s district rather than the account’s district, so it can count accounts whose branch location is not 1, violating the explicit branch-location requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 462,
    "result": {
      "judgement": "Predicted query returns the correct Italian set translations, differing from gold only by an extra duplicate which is harmless for a list question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 226,
    "result": {
      "judgement": "The predicted query correctly computes the percentage of double bonds for molecule TR008 with equivalent logic and no unsupported filters.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 427,
    "result": {
      "judgement": "Predicted query correctly lists the languages for set code ARC with mcmName 'Archenemy'; differences are immaterial (DISTINCT and column side of equality).",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 281,
    "result": {
      "judgement": "Predicted query counts each element among 4th atoms of carcinogenic molecules exactly as the question’s “tally” asks, using the evidence-specified substring test; gold only lists distinct elements (no counts) so misses the tally requirement. Thus the prediction is acceptable and should not be overturned.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 17,
    "result": {
      "judgement": "Predicted query correctly lists all schools with AvgScrWrite > 499, filtered to non-null charter numbers and ordered by writing score, which satisfies the requested ranking; explicit rank column is not required by the question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 472,
    "result": {
      "judgement": "Predicted query correctly counts Ice Age sets with Italian translations; any difference in counting id vs code is immaterial.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 477,
    "result": {
      "judgement": "Prediction matches the intent: it lists which of the three artists appear on any card whose set name is Coldsnap, so it fulfills the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 486,
    "result": {
      "judgement": "Predicted query correctly computes percentage of cards with converted mana cost 7 within the Coldsnap set using proper join and aggregation.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 47,
    "result": {
      "judgement": "Predicted query matches the question’s filters (County Alameda, DOC 52, open year 1980) and divides by 12, so it correctly returns the requested monthly average.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 24,
    "result": {
      "judgement": "Prediction satisfies both conditions and returns correct school names, matching gold result; no schema or semantic errors found.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 522,
    "result": {
      "judgement": "Predicted query applies correct filters and joins to fetch card name with banned formats; extra duplicate rows are acceptable for a list question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 213,
    "result": {
      "judgement": "Prediction correctly retrieves the bond_type for the bond connecting TR004_8 and TR004_20, matching the question requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 249,
    "result": {
      "judgement": "Predicted query correctly returns the elements for the atoms in bond TR144_8_19, merely duplicating values, which is permissible for a list question.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 201,
    "result": {
      "judgement": "Prediction counts only atoms directly participating in double bonds, whereas the question asks for all atoms in molecules that contain a double bond, so the percentage is wrong.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 36,
    "result": {
      "judgement": "Prediction returns full names of all administrators of the school with the highest NumGE1500, satisfying question requirements; no substantive error found.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 234,
    "result": {
      "judgement": "Predicted query correctly counts bonds of molecule TR009 that involve atom 12, while gold wrongly filters for atoms 1 and 2, so prediction is valid and gold is faulty.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 50,
    "result": {
      "judgement": "Prediction outputs the physical Street field instead of the requested postal/mailing street (MailStreet), violating the explicit requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 424,
    "result": {
      "judgement": "Predicted query correctly computes the percentage of cards that are textless with normal layout; any COUNT vs SUM difference is semantically equivalent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 230,
    "result": {
      "judgement": "Predicted query correctly lists the molecule's element values together with its label; duplicates are acceptable since the question does not demand distinctness.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 125,
    "result": {
      "judgement": "Prediction correctly lists each relevant district with its region (state) and the computed unemployment-rate increment for all running-debt loans, whereas the gold query omits the requested district and state fields.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 243,
    "result": {
      "judgement": "Predicted query correctly returns bonds that connect a phosphorus atom with a nitrogen atom and adds no unwarranted restrictions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 469,
    "result": {
      "judgement": "Prediction sensibly answers the yes/no intent by checking if any Angel of Mercy set has a non-null mtgoCode, matching a plausible reading of the question.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 247,
    "result": {
      "judgement": "Prediction correctly filters atoms absent from both columns of connected and returns their elements (extra atom_id column is benign), while gold ignores atoms bonded as atom_id2 and is therefore incorrect.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 260,
    "result": {
      "judgement": "Prediction narrows to atoms actually in triple bonds, which is a plausible reading of \"atoms with triple-bond molecules\" and yields identical results, so no clear violation.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 87,
    "result": {
      "judgement": "Predicted query meets all stated filters and correctly returns the administrator email fields, only adding a nullable third column which is harmless; no clear error warrants overturning.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 25,
    "result": {
      "judgement": "Prediction filters by city whereas gold filters by district; both reasonably satisfy the ambiguous phrase “schools in Riverside”, and other logic matches the requirement, so no clear error in predicted SQL.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 194,
    "result": {
      "judgement": "Prediction matches required filters and calculates age identically to gold; no unwarranted predicates or omissions.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 484,
    "result": {
      "judgement": "Prediction ignores the language filter when determining the maximum CMC, so it looks for Italian names of cards whose CMC exceeds that of any card with Italian translation and returns none; therefore it does not answer the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 39,
    "result": {
      "judgement": "“Fresno schools” can reasonably mean schools located in the city of Fresno (pred) or schools in Fresno County (gold); both queries otherwise meet the date and averaging requirements, so the prediction is a valid alternative interpretation.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 23,
    "result": {
      "judgement": "Predicted query wrongly takes absolute difference, admitting cases where (K-12 − Ages 5-17) is < −30, violating the defined positive-difference requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 100,
    "result": {
      "judgement": "“Account opened” can reasonably be read as customers who actually opened (i.e., own) an account, so the prediction’s extra OWNER join is a valid interpretation; the discrepancy stems from question ambiguity, not an error.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 195,
    "result": {
      "judgement": "Prediction returns the correct bond_type and the question doesn’t forbid including its count, so semantics are satisfied.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 212,
    "result": {
      "judgement": "Predicted query counts total atom occurrences while gold counts distinct molecules; the question is ambiguous about the counting basis, so prediction remains a reasonable interpretation.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 89,
    "result": {
      "judgement": "The prediction adds an INNER JOIN to disp with a type='OWNER' filter that removes all matching accounts, producing 0 instead of the correct count 13 required by the question.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 37,
    "result": {
      "judgement": "Predicted query includes schools where NumGE1500 is NULL, so it picks a school whose excellence rate is undefined rather than the true minimum defined rate; thus it answers a different question than asked.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 228,
    "result": {
      "judgement": "Prediction correctly computes the percentage of hydrogen atoms in molecule TR206 rounded to four decimals, matching question intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 48,
    "result": {
      "judgement": "Predicted query correctly counts merged Unified (DOC=54) and merged Elementary (DOC=52) schools in Orange County and returns their ratio, matching the question’s intent.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 242,
    "result": {
      "judgement": "Predicted query applies the correct carcinogenic filter and uses the specified substring positions 7-8 to restrict atoms 21-25, so it satisfies the question equally to the gold.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 112,
    "result": {
      "judgement": "Predicted query reasonably gets the account’s district for that client and the extra OWNER filter is defensible; no explicit requirement is violated so we keep the pass.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 255,
    "result": {
      "judgement": "Predicted query correctly computes the percentage of single bonds whose molecules are labeled carcinogenic with five-decimal rounding, matching the question’s requirements.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 5,
    "result": {
      "judgement": "Prediction correctly counts schools with AvgScrMath > 400 and Virtual = 'F', satisfying the question; using CDSCode for distinct is acceptable.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 99,
    "result": {
      "judgement": "Predicted query satisfies all stated filters and returns the account(s) (plus extra harmless columns) whose loan amount is maximal, matching the gold result.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 120,
    "result": {
      "judgement": "Predicted query satisfies the timeframe, restricts to owners, and filters by east Bohemia using the client’s region—a reasonable reading of “account holders”; no explicit requirement is violated.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 129,
    "result": {
      "judgement": "Prediction correctly lists the ten largest January-1996 withdrawals with their district names, while the gold query merely picks ten districts alphabetically regardless of amount.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 128,
    "result": {
      "judgement": "Prediction counts female clients who are account owners per district and lists the top nine; this matches a reasonable reading of 'female account holders', whereas the gold simply counts all female clients, so prediction is acceptable.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 169,
    "result": {
      "judgement": "Predicted query correctly computes the year-over-year growth for loans tied to male clients; the extra OWNER filter in the gold is a reasonable but not mandated interpretation, so the prediction remains semantically valid.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 159,
    "result": {
      "judgement": "Predicted query correctly returns all transactions for client 3356 where operation is 'VYBER'; extra columns are permissible for a listing.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 41,
    "result": {
      "judgement": "Predicted query matches question requirements using same filters and ranking logic as gold; no violations found.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 28,
    "result": {
      "judgement": "Prediction returns the same set of locally-funded schools with the correct difference filter and outputs the School name plus the text field DOCType, which matches the phrasing “DOC type”; the gold returns the numeric DOC code instead, so the prediction remains acceptable.",
      "verdict": false,
      "ambiguity": "ambiguous question",
      "gold_correct": true
    }
  },
  {
    "question_id": 45,
    "result": {
      "judgement": "Predicted query satisfies the question, correctly finding schools managed by Ricci Ulrich and giving their average writing scores.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 79,
    "result": {
      "judgement": "Prediction meets the stated need, correctly counts F-virtual schools in the two counties and returns the top county with its count.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 138,
    "result": {
      "judgement": "Predicted query wrongly derives the second-highest district by merely taking the 2nd row of the sorted list, so if multiple districts tie for the top crime count it will return a top-crime district instead of a true second-highest; this violates the explicit 'second-highest' requirement.",
      "verdict": true,
      "ambiguity": "na",
      "gold_correct": false
    }
  },
  {
    "question_id": 117,
    "result": {
      "judgement": "Predicted query correctly computes the percentage of loan amount with status 'A', matching the intended calculation.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 186,
    "result": {
      "judgement": "Predicted query correctly computes the share of male clients among all clients with frequency = 'POPLATEK TYDNE', matching the question; differences with gold are minor and stem from duplicate-handling, not an error.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": true
    }
  },
  {
    "question_id": 145,
    "result": {
      "judgement": "Prediction correctly returns distinct client (account holder) IDs with credit-card withdrawals in 1998 whose amounts are below the average of such credit-card transactions, matching the question, whereas the gold returns account IDs and uses a broader average, so gold is likely wrong.",
      "verdict": false,
      "ambiguity": "na",
      "gold_correct": false
    }
  }
]